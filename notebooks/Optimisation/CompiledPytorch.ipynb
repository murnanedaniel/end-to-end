{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_add\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Get rid of RuntimeWarnings, gross\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "from lightning_modules.GNN.utils import make_mlp\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir= \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml-codalab/embedding_processed/1_pt_cut_endcaps_unweighted_augmented/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_events = 10\n",
    "all_events = os.listdir(input_dir)\n",
    "loaded_events = [torch.load(os.path.join(input_dir,event)) for event in all_events[:num_events]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(loaded_events, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     73
    ]
   },
   "outputs": [],
   "source": [
    "class MPNN_Network(nn.Module):\n",
    "    \"\"\"\n",
    "    A message-passing graph network which takes a graph with:\n",
    "    - bi-directional edges\n",
    "    - node features, no edge features\n",
    "\n",
    "    and applies the following modules:\n",
    "    - a graph encoder (no message passing)\n",
    "    - recurrent edge and node networks\n",
    "    - an edge classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_node_dim, in_layers, node_layers, edge_layers,\n",
    "                 n_graph_iters=1, layer_norm=True):\n",
    "        super(MPNN_Network, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "\n",
    "        # The node encoder transforms input node features to the hidden space\n",
    "        self.node_encoder = make_mlp(input_dim, [hidden_node_dim]*in_layers)\n",
    "\n",
    "        # The edge network computes new edge features from connected nodes\n",
    "        # self.edge_network = make_mlp(2*hidden_node_dim,\n",
    "        #                              [hidden_edge_dim]*edge_layers,\n",
    "        #                              layer_norm=layer_norm)\n",
    "\n",
    "        # The node network computes new node features\n",
    "        self.node_network = make_mlp(2*hidden_node_dim,\n",
    "                                     [hidden_node_dim]*node_layers,\n",
    "                                     layer_norm=layer_norm)\n",
    "\n",
    "        # The edge classifier computes final edge scores\n",
    "        self.edge_classifier = make_mlp(2*hidden_node_dim,\n",
    "                                        [hidden_node_dim, hidden_node_dim, 1],\n",
    "                                        output_activation=None)\n",
    "        \n",
    "#         self.conv1 = GCNConv(input_dim, hidden_node_dim).jittable()\n",
    "#         self.conv2 = GCNConv(hidden_node_dim, hidden_node_dim).jittable()\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        start, end = edge_index[0], edge_index[1]\n",
    "\n",
    "        # Encode the graph features into the hidden space\n",
    "        x = self.node_encoder(x)\n",
    "\n",
    "        src = x[end]\n",
    "        index = start.unsqueeze(-1)\n",
    "        in_messages = torch.zeros(x.shape, dtype=src.dtype).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "        \n",
    "        src = x[start]\n",
    "        index = end.unsqueeze(-1)\n",
    "        out_messages = torch.zeros(x.shape, dtype=src.dtype).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "        \n",
    "        aggr_messages = in_messages + out_messages\n",
    "        \n",
    "        #     # Compute new node features\n",
    "        node_inputs = torch.cat([x, aggr_messages], dim=1)\n",
    "        x = self.node_network(node_inputs)\n",
    "\n",
    "\n",
    "        # Compute final edge scores; use original edge directions only\n",
    "        clf_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        return self.edge_classifier(clf_inputs).squeeze(-1)\n",
    "\n",
    "class Simple_Network(nn.Module):\n",
    "    \"\"\"\n",
    "    A message-passing graph network which takes a graph with:\n",
    "    - bi-directional edges\n",
    "    - node features, no edge features\n",
    "\n",
    "    and applies the following modules:\n",
    "    - a graph encoder (no message passing)\n",
    "    - recurrent edge and node networks\n",
    "    - an edge classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_node_dim, in_layers, node_layers, edge_layers,\n",
    "                 n_graph_iters=1, layer_norm=True):\n",
    "        super(Simple_Network, self).__init__()\n",
    "        self.n_graph_iters = n_graph_iters\n",
    "\n",
    "        # The node encoder transforms input node features to the hidden space\n",
    "        self.node_encoder = make_mlp(input_dim, [hidden_node_dim]*in_layers)\n",
    "\n",
    "        # The edge network computes new edge features from connected nodes\n",
    "        # self.edge_network = make_mlp(2*hidden_node_dim,\n",
    "        #                              [hidden_edge_dim]*edge_layers,\n",
    "        #                              layer_norm=layer_norm)\n",
    "\n",
    "        # The node network computes new node features\n",
    "        self.node_network = make_mlp(hidden_node_dim,\n",
    "                                     [hidden_node_dim]*node_layers,\n",
    "                                     layer_norm=layer_norm)\n",
    "\n",
    "        # The edge classifier computes final edge scores\n",
    "        self.edge_classifier = make_mlp(2*hidden_node_dim,\n",
    "                                        [hidden_node_dim, hidden_node_dim, 1],\n",
    "                                        output_activation=None)\n",
    "\n",
    "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
    "        start, end = edge_index[0], edge_index[1]\n",
    "\n",
    "        # Encode the graph features into the hidden space\n",
    "        x = self.node_encoder(x)\n",
    "\n",
    "        # Loop over graph iterations\n",
    "        for i in range(self.n_graph_iters):\n",
    "\n",
    "            # Previous hidden state\n",
    "            x0 = x\n",
    "\n",
    "            # Sum edge features coming into each node\n",
    "            # aggr_messages = scatter_add(x[end], start, dim=0, dim_size=x.shape[0]) + scatter_add(x[start], end, dim=0, dim_size=x.shape[0])\n",
    "\n",
    "            # Compute new node features\n",
    "            # node_inputs = torch.cat([x, aggr_messages], dim=1)\n",
    "            x = self.node_network(x)\n",
    "\n",
    "            # Residual connection\n",
    "            x = x + x0\n",
    "\n",
    "        # Compute final edge scores; use original edge directions only\n",
    "        clf_inputs = torch.cat([x[start], x[end]], dim=1)\n",
    "        return self.edge_classifier(clf_inputs).squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = batch.to(device)\n",
    "        pred = model(data.x, data.edge_index)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float(), pos_weight=torch.tensor(weight))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
    "        total += len(pred)\n",
    "    acc = correct/total\n",
    "    return acc, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_loss_v = []\n",
    "t_acc_v = []\n",
    "v_loss_v = []\n",
    "v_acc_v = []\n",
    "ep = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Accuracy: 0.8287\n",
      "Epoch: 2, Accuracy: 0.8287\n",
      "Epoch: 3, Accuracy: 0.8287\n",
      "Epoch: 4, Accuracy: 0.8287\n",
      "Epoch: 5, Accuracy: 0.8295\n",
      "Epoch: 6, Accuracy: 0.8310\n",
      "Epoch: 7, Accuracy: 0.8309\n",
      "Epoch: 8, Accuracy: 0.8309\n",
      "Epoch: 9, Accuracy: 0.8309\n",
      "Epoch: 10, Accuracy: 0.8307\n"
     ]
    }
   ],
   "source": [
    "weight = 2\n",
    "m_configs = {\"input_dim\": 3, \"hidden_node_dim\": 64, \"in_layers\": 3, \"node_layers\": 3, \"edge_layers\": 3, \"n_graph_iters\": 8, \"layer_norm\": True}\n",
    "mpnn_model = MPNN_Network(**m_configs).to(device)\n",
    "optimizer = torch.optim.Adam(mpnn_model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
    "for epoch in range(10):\n",
    "    ep += 1  \n",
    "    mpnn_model.train()\n",
    "    acc, total_loss = train(mpnn_model, train_loader, optimizer)\n",
    "    t_loss_v.append(total_loss)\n",
    "    t_acc_v.append(acc)\n",
    "\n",
    "\n",
    "    print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Accuracy: 0.8221\n",
      "Epoch: 3, Accuracy: 0.8280\n",
      "Epoch: 4, Accuracy: 0.8291\n",
      "Epoch: 5, Accuracy: 0.8257\n",
      "Epoch: 6, Accuracy: 0.8403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8006092b9bda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msimple_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mt_loss_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt_acc_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-dcebf84fd828>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weight = 2\n",
    "m_configs = {\"input_dim\": 3, \"hidden_node_dim\": 64, \"in_layers\": 3, \"node_layers\": 3, \"edge_layers\": 3, \"n_graph_iters\": 8, \"layer_norm\": True}\n",
    "simple_model = Simple_Network(**m_configs).to(device)\n",
    "optimizer = torch.optim.Adam(simple_model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
    "for epoch in range(10):\n",
    "    ep += 1  \n",
    "    simple_model.train()\n",
    "    acc, total_loss = train(simple_model, train_loader, optimizer)\n",
    "    t_loss_v.append(total_loss)\n",
    "    t_acc_v.append(acc)\n",
    "\n",
    "    print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Scatter_add testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nodes = torch.rand((10,2))\n",
    "edges = torch.randint(10, (2, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3532, 0.5300],\n",
       "        [0.3755, 0.8037],\n",
       "        [0.3916, 0.2947],\n",
       "        [0.1680, 0.2666],\n",
       "        [0.1674, 0.5123],\n",
       "        [0.0464, 0.4204],\n",
       "        [0.2450, 0.2764],\n",
       "        [0.2899, 0.7279],\n",
       "        [0.2734, 0.2199],\n",
       "        [0.5983, 0.8264]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 6, 4, 1, 8, 3],\n",
       "        [2, 2, 9, 6, 9, 7]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src = nodes[edges[0]]\n",
    "index = edges[1].unsqueeze(-1)\n",
    "aggr_messages = torch.zeros(nodes.shape, dtype=src.dtype).to(device).scatter_add(0, index, src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2899, 0.7279],\n",
       "        [0.2450, 0.2764],\n",
       "        [0.1674, 0.5123],\n",
       "        [0.3755, 0.8037],\n",
       "        [0.2734, 0.2199],\n",
       "        [0.1680, 0.2666]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7],\n",
       "        [6],\n",
       "        [4],\n",
       "        [1],\n",
       "        [8],\n",
       "        [3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.5350, 1.0043],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.3755, 0.8037],\n",
       "        [0.1680, 0.2666],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.4408, 0.7322]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(nodes.shape, dtype=src.dtype).to(device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7],\n",
       "        [6, 6],\n",
       "        [4, 4],\n",
       "        [1, 1],\n",
       "        [8, 8],\n",
       "        [3, 3]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.repeat((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.3755, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.1680, 0.0000],\n",
       "        [0.1674, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.2450, 0.0000],\n",
       "        [0.2899, 0.0000],\n",
       "        [0.2734, 0.0000],\n",
       "        [0.0000, 0.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggr_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.5350, 1.0043],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.3755, 0.8037],\n",
       "        [0.1680, 0.2666],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.4408, 0.7322]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_add(nodes[edges[0]], edges[1], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_module = torch.jit.script(MPNN_Network(**m_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=MPNN_Network\n",
       "  (node_encoder): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "    (1): RecursiveScriptModule(original_name=ReLU)\n",
       "    (2): RecursiveScriptModule(original_name=Linear)\n",
       "    (3): RecursiveScriptModule(original_name=ReLU)\n",
       "    (4): RecursiveScriptModule(original_name=Linear)\n",
       "    (5): RecursiveScriptModule(original_name=ReLU)\n",
       "  )\n",
       "  (node_network): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "    (1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "    (2): RecursiveScriptModule(original_name=ReLU)\n",
       "    (3): RecursiveScriptModule(original_name=Linear)\n",
       "    (4): RecursiveScriptModule(original_name=LayerNorm)\n",
       "    (5): RecursiveScriptModule(original_name=ReLU)\n",
       "    (6): RecursiveScriptModule(original_name=Linear)\n",
       "    (7): RecursiveScriptModule(original_name=LayerNorm)\n",
       "    (8): RecursiveScriptModule(original_name=ReLU)\n",
       "  )\n",
       "  (edge_classifier): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(original_name=Linear)\n",
       "    (1): RecursiveScriptModule(original_name=ReLU)\n",
       "    (2): RecursiveScriptModule(original_name=Linear)\n",
       "    (3): RecursiveScriptModule(original_name=ReLU)\n",
       "    (4): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.trace(mpnn_model, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNN_Network(\n",
       "  original_name=MPNN_Network\n",
       "  (node_encoder): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): ReLU(original_name=ReLU)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): ReLU(original_name=ReLU)\n",
       "    (4): Linear(original_name=Linear)\n",
       "    (5): ReLU(original_name=ReLU)\n",
       "  )\n",
       "  (node_network): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): LayerNorm(original_name=LayerNorm)\n",
       "    (2): ReLU(original_name=ReLU)\n",
       "    (3): Linear(original_name=Linear)\n",
       "    (4): LayerNorm(original_name=LayerNorm)\n",
       "    (5): ReLU(original_name=ReLU)\n",
       "    (6): Linear(original_name=Linear)\n",
       "    (7): LayerNorm(original_name=LayerNorm)\n",
       "    (8): ReLU(original_name=ReLU)\n",
       "  )\n",
       "  (edge_classifier): Sequential(\n",
       "    original_name=Sequential\n",
       "    (0): Linear(original_name=Linear)\n",
       "    (1): ReLU(original_name=ReLU)\n",
       "    (2): Linear(original_name=Linear)\n",
       "    (3): ReLU(original_name=ReLU)\n",
       "    (4): Linear(original_name=Linear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7495, -1.7519, -1.4925,  ...,  0.0104,  0.2420, -1.3107],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traced_script_module(input_data[0], input_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorRT Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data = loaded_events[0]\n",
    "input_data = (example_data.x, example_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/onnx/symbolic_opset9.py:1708: UserWarning: ONNX export unsqueeze with negative axis -1 might cause the onnx model to be incorrect. Negative axis is not supported in ONNX. Axis is converted to 1 based on input shape at export time. Passing an tensor of different rank in execution will be incorrect.\n",
      "  \"Passing an tensor of different rank in execution will be incorrect.\")\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/onnx/symbolic_opset9.py:577: UserWarning: ONNX export squeeze with negative axis -1 might cause the onnx model to be incorrect. Negative axis is not supported in ONNX. Axis is converted to 1 based on input shape at export time. Passing an tensor of different rank in execution will be incorrect.\n",
      "  \"Passing an tensor of different rank in execution will be incorrect.\")\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/onnx/symbolic_opset9.py:599: UserWarning: This model contains a squeeze operation on dimension 1. If the model is intended to be used with dynamic input shapes, please use opset version 11 to export the model.\n",
      "  \"intended to be used with dynamic input shapes, please use opset version 11 to export the model.\")\n"
     ]
    }
   ],
   "source": [
    "ONNX_FILE_PATH = \"simple_model.onnx\"\n",
    "torch.onnx.export(mpnn_model, input_data, ONNX_FILE_PATH, input_names=[\"input\"],\n",
    "                  output_names=[\"output\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.2.2.3'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorrt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pybind11::init(): factory function returned nullptr",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-fd3b717a792f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtensorrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: pybind11::init(): factory function returned nullptr"
     ]
    }
   ],
   "source": [
    "assert tensorrt.Builder(tensorrt.Logger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
