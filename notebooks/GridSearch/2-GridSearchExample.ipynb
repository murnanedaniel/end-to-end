{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Fixed-radius NN Linear-time Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the techniques described in [this paper](https://reader.elsevier.com/reader/sd/pii/0020019077900709?token=E45C0E1870EA26C21C1F149B6090CE4630A51269D324BE1206B7BF2764FB48B2DDC93F4B86FBFBD8CBDED63B15BBC6DA&originRegion=us-east-1&originCreation=20210428165528)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from time import time as tt\n",
    "import importlib\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from itertools import chain\n",
    "from random import shuffle, sample\n",
    "from scipy.optimize import root_scalar as root\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph, radius_graph\n",
    "import trackml.dataset\n",
    "import torch_geometric\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "from sklearn import metrics, decomposition\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import faiss\n",
    "\n",
    "sys.path.append('/global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the lightning module and setup the model to get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "from LightningModules.Embedding.utils import graph_intersection, build_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpt_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/lightning_checkpoints/CodaEmbeddingStudy/pbn07koj\"\n",
    "chkpt_file = \"last.ckpt\"\n",
    "chkpt_path = os.path.join(chkpt_dir, chkpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LayerlessEmbedding.load_from_checkpoint(chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hparams[\"train_split\"] = [100,10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaged and Tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(spatial, pca):\n",
    "    \n",
    "    spatial_pca = torch.from_numpy(pca.transform(spatial.cpu())).float().to(device)\n",
    "\n",
    "    pos_spatial = (spatial_pca - spatial_pca.min(dim=0)[0].T).half()\n",
    "    half_spatial = spatial.half()\n",
    "    spatial_ind = torch.arange(len(pos_spatial), device=device).int()\n",
    "    \n",
    "    L_box = pos_spatial.max()\n",
    "    \n",
    "    return pos_spatial, half_spatial, spatial_ind, L_box\n",
    "\n",
    "def point_locations(pos_spatial, r_max):\n",
    "    \n",
    "    x_cell_ref = (pos_spatial // r_max).int()\n",
    "    \n",
    "    return x_cell_ref\n",
    "    \n",
    "def build_cell_lookup(r_max, L_box, projection_d):\n",
    "    \n",
    "    reshape_dims = [int(L_box // r_max + 1)]*projection_d\n",
    "    cell_index_length = np.product(reshape_dims)\n",
    "    cell_lookup = torch.arange(cell_index_length, device=device, dtype=torch.int).reshape(reshape_dims)\n",
    "\n",
    "    return cell_lookup\n",
    "    \n",
    "def build_point_lookup(x_cell_ref, cell_lookup, nb, projection_d):\n",
    "    \n",
    "    inclusive_nhood = torch.flatten(torch.stack(torch.meshgrid([torch.tensor([-1, 0])]*projection_d)), start_dim=1).T.to(device)\n",
    "    nbhood_map = torch.transpose(x_cell_ref.expand(len(inclusive_nhood), nb, projection_d) + torch.transpose(inclusive_nhood.expand(nb, len(inclusive_nhood), projection_d), 1, 0), 0, 1)\n",
    "    hit_nhood_lookup = cell_lookup[nbhood_map.long().chunk(chunks=projection_d, dim=2)].squeeze()\n",
    "    hit_lookup = cell_lookup[x_cell_ref.long().chunk(chunks=projection_d, dim=1)].squeeze()\n",
    "    \n",
    "    return hit_lookup, hit_nhood_lookup\n",
    "\n",
    "def find_non_empty_cells(hit_lookup, hit_nhood_lookup):\n",
    "    \n",
    "    _, flat_inverses, flat_counts = torch.unique(hit_nhood_lookup, return_inverse=True, return_counts=True)\n",
    "    non_empty_cells = torch.unique(hit_lookup[(flat_counts[flat_inverses] > 1).any(1)])\n",
    "    \n",
    "    return non_empty_cells\n",
    "    \n",
    "def run_search(r_query, hit_lookup, hit_nhood_lookup, non_empty_cells, half_spatial, spatial_ind):\n",
    "    \n",
    "    all_radius_edges = []\n",
    "    \n",
    "    for cell in non_empty_cells:\n",
    "        x_in_cell = spatial_ind[(hit_lookup == cell)]\n",
    "        x_in_nhood = spatial_ind[(hit_nhood_lookup == cell).any(1)]\n",
    "        if len(x_in_nhood)>0:\n",
    "            all_cell_combinations = torch.flatten(torch.stack(torch.meshgrid(x_in_cell, x_in_nhood)), start_dim=1)\n",
    "            all_radius_edges.append(all_cell_combinations[:, torch.sum( (half_spatial[all_cell_combinations[0].long()] - half_spatial[all_cell_combinations[1].long()])**2, dim=1) < r_query**2])\n",
    "    \n",
    "    return all_radius_edges\n",
    "    \n",
    "def postprocess(all_radius_edges):\n",
    "    \n",
    "    all_radius_edges = torch.cat(all_radius_edges, dim = 1)\n",
    "    all_radius_edges = all_radius_edges[:, all_radius_edges[0] != all_radius_edges[1]]\n",
    "    all_radius_edges = torch.cat([all_radius_edges, all_radius_edges.flip(0)], dim=1)\n",
    "    \n",
    "    return all_radius_edges\n",
    "    \n",
    "def build_edges_grid(spatial, r_query, pca, r_max=None):\n",
    "    \n",
    "    nb = spatial.shape[0] # The number of hits in the event\n",
    "    d = spatial.shape[1] # The dimension of the embedding space\n",
    "    projection_d = pca.n_components # The dimension of the PCA projection\n",
    "    \n",
    "    if r_max is None:\n",
    "        r_max = r_query\n",
    "\n",
    "    # 1. Run PCA transform\n",
    "    pos_spatial, half_spatial, spatial_ind, L_box = pca_transform(spatial, pca)\n",
    "\n",
    "    # 2. Get point locations in search grid\n",
    "    x_cell_ref = point_locations(pos_spatial, r_max)\n",
    "    \n",
    "    # 3. Build cell lookup table\n",
    "    cell_lookup = build_cell_lookup(r_max, L_box, projection_d)\n",
    "\n",
    "    # 4. Build hit lookup table (basically the inverse of the cell lookup table)\n",
    "    hit_lookup, hit_nhood_lookup = build_point_lookup(x_cell_ref, cell_lookup, nb, projection_d)\n",
    "\n",
    "    # 5. Find cells that are not empty\n",
    "    non_empty_cells = find_non_empty_cells(hit_lookup, hit_nhood_lookup)\n",
    "\n",
    "    # 6. Run the search loop over each cell in the grid\n",
    "    all_radius_edges = run_search(r_query, hit_lookup, hit_nhood_lookup, non_empty_cells, half_spatial, spatial_ind)\n",
    "    \n",
    "    # 7. Postprocess the edges to make them symmetrical, and remove self-edges\n",
    "    all_radius_edges = postprocess(all_radius_edges)\n",
    "    \n",
    "    return all_radius_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = model.trainset[0].to(device)\n",
    "with torch.no_grad():\n",
    "    spatial = model(torch.cat([batch.cell_data, batch.x], axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a 2D PCA projection to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA construction\n",
    "projection_d = 2\n",
    "pca = decomposition.PCA(n_components = projection_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 162 ms, sys: 126 ms, total: 289 ms\n",
      "Wall time: 162 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pca.fit(spatial.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time the Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `r_cell` (which is the size of the grid spacing) and `r_max` (which is the radius to construct a graph from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cell = 1\n",
    "r_max = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 12.2 s, total: 42.9 s\n",
      "Wall time: 31.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "timelist = []\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        tic = tt()\n",
    "        batch = model.trainset[i].to(device)\n",
    "        spatial = model(torch.cat([batch.cell_data, batch.x], axis=-1))\n",
    "        e_spatial = build_edges_grid(spatial, r_max, pca, r_cell)\n",
    "        timelist.append(tt() - tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time mean: 0.3173021197319031 +- 0.060290047426455766\n"
     ]
    }
   ],
   "source": [
    "print(f'Time mean: {np.mean(timelist)} +- {np.std(timelist)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
