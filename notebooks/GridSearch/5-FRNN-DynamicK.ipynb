{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking FRNN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the techniques described in [this paper](https://reader.elsevier.com/reader/sd/pii/0020019077900709?token=E45C0E1870EA26C21C1F149B6090CE4630A51269D324BE1206B7BF2764FB48B2DDC93F4B86FBFBD8CBDED63B15BBC6DA&originRegion=us-east-1&originCreation=20210428165528)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from time import time as tt\n",
    "import importlib\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "# from torch_geometric.data import DataLoader\n",
    "\n",
    "from itertools import chain\n",
    "from random import shuffle, sample\n",
    "from scipy.optimize import root_scalar as root\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "import trackml.dataset\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "from sklearn import metrics, decomposition\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import faiss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Model and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load the lightning module and setup the model to get the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "CHANGE THE EXATRKX PIPELINE LOCATION TO YOUR PARTICULAR LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exatrkx_pipeline = '/global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example'\n",
    "sys.path.append(exatrkx_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "from LightningModules.Embedding.utils import graph_intersection, build_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load model for inference (if data not already saved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "CHANGE THE CHECKPOINT DIRECTORY TO YOUR PARTICULAR LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chkpt_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/lightning_checkpoints/CodaEmbeddingStudy/pbn07koj\"\n",
    "chkpt_file = \"last.ckpt\"\n",
    "chkpt_path = os.path.join(chkpt_dir, chkpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = LayerlessEmbedding.load_from_checkpoint(chkpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.hparams[\"train_split\"] = [100,10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FRNN Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prepare and save input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = model.trainset[0].to(device)\n",
    "with torch.no_grad():\n",
    "    spatial = model(torch.cat([batch.cell_data, batch.x], axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch.spatial = spatial\n",
    "torch.save(batch, \"example_event.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Load saved input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = torch.load(\"example_event.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spatial = batch.spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Run FRNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import frnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "r = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "for now only grid in 2D/3D is supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exatrkx-test/lib/python3.7/site-packages/frnn-0.0.0-py3.7-linux-x86_64.egg/frnn/frnn.py\u001b[0m in \u001b[0;36mfrnn_grid_points\u001b[0;34m(points1, points2, lengths1, lengths2, K, r, grid, return_nn, return_sorted, radius_cell_ratio)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dimension mismatch: points1 of dimension {points1.shape[2]} while points2 of dimension {points2.shape[2]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"for now only grid in 2D/3D is supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpoints2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"for now only cuda version is supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: for now only grid in 2D/3D is supported"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# first time there is no cached grid\n",
    "dists, idxs, nn, grid = frnn.frnn_grid_points(\n",
    "    points1=spatial.unsqueeze(0), points2=spatial.unsqueeze(0), lengths1=None, lengths2=None, K=32, r=r, grid=None, return_nn=False, return_sorted=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.53 ms, sys: 0 ns, total: 1.53 ms\n",
      "Wall time: 1.09 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dists, idxs, nn, grid = frnn.frnn_grid_points(\n",
    "    points1=spatial.unsqueeze(0), points2=spatial.unsqueeze(0), lengths1=None, lengths2=None, K=32, r=r, grid=grid, return_nn=False, return_sorted=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove the unneccessary batch dimension\n",
    "idxs = idxs.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Convert the array of IDs into an edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ind = torch.Tensor.repeat(torch.arange(idxs.shape[0], device=device), (idxs.shape[1], 1), 1).T\n",
    "positive_idxs = idxs >= 0\n",
    "edge_list = torch.stack([ind[positive_idxs], idxs[positive_idxs]])\n",
    "\n",
    "# Remove self-loops\n",
    "e_spatial = edge_list[:, edge_list[0] != edge_list[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Accuracy Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e_bidir = torch.cat([batch.layerless_true_edges, batch.layerless_true_edges.flip(0)], axis=-1) \n",
    "e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir, using_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = e_bidir.shape[1]\n",
    "tp = y_cluster.sum()\n",
    "p = e_spatial.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency: 0.027304455637931824, Purity: 0.0021169965621083975\n"
     ]
    }
   ],
   "source": [
    "print(f'Efficiency: {tp / t}, Purity: {tp / p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FAISS Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch\n",
    "import faiss.contrib.torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "D, I = faiss.knn_gpu(res, spatial, spatial, K)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end.record()\n",
    "time = start.elapsed_time(end)\n",
    "print(f\"Time taken: {time:.5}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweaking FRNN Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import frnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "d = 3\n",
    "spatial = torch.rand(N, d).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.3\n",
    "K = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacking Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC2 Grid Count: tensor([[313, 332, 327, 347, 345, 317, 220, 312, 363, 373, 327, 340, 326, 212,\n",
      "         360, 319, 334, 324, 354, 341, 227, 300, 324, 326, 318, 346, 333, 237,\n",
      "         332, 363, 327, 335, 320, 324, 233, 336, 342, 352, 363, 364, 325, 228,\n",
      "         240, 236, 205, 221, 239, 222, 150, 330, 349, 332, 326, 366, 318, 220,\n",
      "         322, 321, 357, 330, 334, 347, 238, 323, 308, 370, 375, 350, 329, 240,\n",
      "         326, 348, 321, 340, 363, 310, 207, 367, 368, 342, 303, 372, 322, 224,\n",
      "         345, 325, 350, 334, 287, 322, 208, 254, 224, 216, 236, 211, 221, 136,\n",
      "         346, 340, 308, 338, 358, 354, 222, 342, 339, 366, 327, 354, 319, 235,\n",
      "         351, 327, 322, 341, 326, 314, 238, 343, 356, 315, 333, 312, 344, 273,\n",
      "         357, 306, 322, 367, 342, 336, 223, 333, 364, 358, 332, 329, 304, 217,\n",
      "         226, 240, 246, 220, 225, 221, 146, 344, 357, 302, 352, 344, 335, 228,\n",
      "         361, 338, 343, 327, 337, 358, 231, 377, 358, 341, 349, 352, 325, 240,\n",
      "         338, 357, 327, 335, 329, 329, 212, 295, 326, 320, 321, 367, 382, 232,\n",
      "         387, 319, 304, 325, 313, 344, 241, 184, 247, 221, 252, 248, 226, 159,\n",
      "         356, 327, 315, 287, 330, 348, 235, 365, 296, 327, 362, 312, 309, 219,\n",
      "         337, 324, 363, 356, 342, 331, 223, 349, 360, 327, 318, 347, 316, 237,\n",
      "         348, 320, 336, 323, 353, 324, 250, 348, 315, 316, 322, 324, 332, 242,\n",
      "         203, 214, 223, 214, 230, 225, 154, 307, 345, 325, 351, 347, 310, 230,\n",
      "         336, 345, 344, 325, 322, 339, 238, 376, 352, 337, 345, 327, 378, 223,\n",
      "         380, 358, 335, 365, 339, 299, 228, 292, 327, 305, 379, 330, 361, 247,\n",
      "         343, 338, 325, 339, 325, 316, 238, 233, 239, 213, 235, 230, 207, 149,\n",
      "         241, 222, 197, 216, 202, 229, 141, 221, 212, 220, 225, 241, 234, 131,\n",
      "         235, 237, 225, 211, 231, 222, 152, 236, 223, 240, 207, 225, 247, 141,\n",
      "         228, 220, 218, 225, 211, 222, 154, 229, 248, 215, 234, 235, 222, 143,\n",
      "         153, 161, 173, 144, 139, 147,  87]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "PC1 Grid Count: tensor([[313, 332, 327, 347, 345, 317, 220, 312, 363, 373, 327, 340, 326, 212,\n",
      "         360, 319, 334, 324, 354, 341, 227, 300, 324, 326, 318, 346, 333, 237,\n",
      "         332, 363, 327, 335, 320, 324, 233, 336, 342, 352, 363, 364, 325, 228,\n",
      "         240, 236, 205, 221, 239, 222, 150, 330, 349, 332, 326, 366, 318, 220,\n",
      "         322, 321, 357, 330, 334, 347, 238, 323, 308, 370, 375, 350, 329, 240,\n",
      "         326, 348, 321, 340, 363, 310, 207, 367, 368, 342, 303, 372, 322, 224,\n",
      "         345, 325, 350, 334, 287, 322, 208, 254, 224, 216, 236, 211, 221, 136,\n",
      "         346, 340, 308, 338, 358, 354, 222, 342, 339, 366, 327, 354, 319, 235,\n",
      "         351, 327, 322, 341, 326, 314, 238, 343, 356, 315, 333, 312, 344, 273,\n",
      "         357, 306, 322, 367, 342, 336, 223, 333, 364, 358, 332, 329, 304, 217,\n",
      "         226, 240, 246, 220, 225, 221, 146, 344, 357, 302, 352, 344, 335, 228,\n",
      "         361, 338, 343, 327, 337, 358, 231, 377, 358, 341, 349, 352, 325, 240,\n",
      "         338, 357, 327, 335, 329, 329, 212, 295, 326, 320, 321, 367, 382, 232,\n",
      "         387, 319, 304, 325, 313, 344, 241, 184, 247, 221, 252, 248, 226, 159,\n",
      "         356, 327, 315, 287, 330, 348, 235, 365, 296, 327, 362, 312, 309, 219,\n",
      "         337, 324, 363, 356, 342, 331, 223, 349, 360, 327, 318, 347, 316, 237,\n",
      "         348, 320, 336, 323, 353, 324, 250, 348, 315, 316, 322, 324, 332, 242,\n",
      "         203, 214, 223, 214, 230, 225, 154, 307, 345, 325, 351, 347, 310, 230,\n",
      "         336, 345, 344, 325, 322, 339, 238, 376, 352, 337, 345, 327, 378, 223,\n",
      "         380, 358, 335, 365, 339, 299, 228, 292, 327, 305, 379, 330, 361, 247,\n",
      "         343, 338, 325, 339, 325, 316, 238, 233, 239, 213, 235, 230, 207, 149,\n",
      "         241, 222, 197, 216, 202, 229, 141, 221, 212, 220, 225, 241, 234, 131,\n",
      "         235, 237, 225, 211, 231, 222, 152, 236, 223, 240, 207, 225, 247, 141,\n",
      "         228, 220, 218, 225, 211, 222, 154, 229, 248, 215, 234, 235, 222, 143,\n",
      "         153, 161, 173, 144, 139, 147,  87]], device='cuda:0',\n",
      "       dtype=torch.int32)\n",
      "Grid params: tensor([[2.5868e-05, 1.6212e-05, 1.9670e-06, 6.6667e+00, 7.0000e+00, 7.0000e+00,\n",
      "         7.0000e+00, 3.4300e+02]])\n",
      "\n",
      "Time taken: 198.89ms\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "\n",
    "# first time there is no cached grid\n",
    "dists, idxs, nn, grid = frnn.frnn_grid_points(\n",
    "    points1=spatial.unsqueeze(0), points2=spatial.unsqueeze(0), lengths1=None, lengths2=None, K=K, r=r, grid=None, return_nn=False, return_sorted=True\n",
    ")\n",
    "\n",
    "# Remove the unneccessary batch dimension\n",
    "idxs = idxs.squeeze()\n",
    "\n",
    "ind = torch.Tensor.repeat(torch.arange(idxs.shape[0], device=device), (idxs.shape[1], 1), 1).T\n",
    "positive_idxs = idxs >= 0\n",
    "edge_list = torch.stack([ind[positive_idxs], idxs[positive_idxs]])\n",
    "\n",
    "# Remove self-loops\n",
    "e_spatial = edge_list[:, edge_list[0] != edge_list[1]]\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end.record()\n",
    "time = start.elapsed_time(end)\n",
    "print(f\"Time taken: {time:.5}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Can we estimate worst-case from grid in 8 dimensions, assign K to that worst-case, then scan in 3 dimensions? This would give the most accurate K, while only running in low-D time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 99996773])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9999900])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FRNNTest",
   "language": "python",
   "name": "frnn-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
