{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Fixed-radius NN Linear-time Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the techniques described in [this paper](https://reader.elsevier.com/reader/sd/pii/0020019077900709?token=E45C0E1870EA26C21C1F149B6090CE4630A51269D324BE1206B7BF2764FB48B2DDC93F4B86FBFBD8CBDED63B15BBC6DA&originRegion=us-east-1&originCreation=20210428165528)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from time import time as tt\n",
    "import importlib\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from itertools import chain\n",
    "from random import shuffle, sample\n",
    "from scipy.optimize import root_scalar as root\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph, radius_graph\n",
    "import trackml.dataset\n",
    "import torch_geometric\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "from sklearn import metrics, decomposition\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import faiss\n",
    "\n",
    "sys.path.append('/global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/Pipelines/TrackML_Example')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = 10*torch.rand(1000, 3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Max K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 1\n",
    "r_query = 1\n",
    "nb = spatial.shape[0]\n",
    "d = spatial.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_spatial = (spatial - spatial.min(dim=0)[0].T).half()\n",
    "spatial_ind = torch.arange(len(pos_spatial), device=device).int()\n",
    "L_box = pos_spatial.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cell_ref = (pos_spatial // r_max).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 µs, sys: 403 µs, total: 679 µs\n",
      "Wall time: 446 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "unique_cells, counts = x_cell_ref.unique(dim=0, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_dims = [int(L_box // r_max + 1)]*d\n",
    "cell_index_length = np.product(reshape_dims)\n",
    "cell_lookup = torch.arange(cell_index_length, device=device, dtype=torch.int).reshape(reshape_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "inner_cells = torch.flatten(torch.stack(torch.meshgrid([torch.arange(1, unique_cells.max()).to(device)]*d)), start_dim=1).T\n",
    "print(inner_cells.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusive_nhood = torch.flatten(torch.stack(torch.meshgrid([torch.tensor([-1, 0, 1])]*d)), start_dim=1).T.to(device)\n",
    "nbhood_map = torch.transpose(inner_cells.expand(len(inclusive_nhood), len(inner_cells), d) + torch.transpose(inclusive_nhood.expand(len(inner_cells), len(inclusive_nhood), d), 1, 0), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_nhood_lookup = cell_lookup[nbhood_map.long().chunk(chunks=d, dim=2)].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_lookup = cell_lookup[unique_cells.long().chunk(chunks=d, dim=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 27])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_nhood_lookup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_lookup = torch.zeros(cell_nhood_lookup.max()+1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_lookup[unique_lookup.long().squeeze(-1)] = torch.arange(len(unique_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   0,   3,   4,   5,   0,   0,   6,   7,   8,   0,   0,\n",
       "          9,  10,  11,  12,  13,  14,   0,   0,   0,  15,  16,   0,  17,  18,\n",
       "         19,   0,   0,   0,   0,   0,  20,  21,  22,  23,  24,   0,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,   0,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,   0,  45,  46,  47,  48,  49,   0,  50,   0,\n",
       "          0,  51,  52,  53,   0,  54,   0,   0,  55,  56,  57,  58,   0,   0,\n",
       "         59,  60,  61,  62,  63,   0,  64,   0,  65,  66,  67,  68,   0,  69,\n",
       "          0,  70,  71,  72,   0,  73,  74,  75,  76,  77,  78,   0,  79,   0,\n",
       "         80,  81,  82,  83,  84,   0,  85,   0,   0,  86,  87,  88,   0,   0,\n",
       "         89,  90,   0,   0,  91,   0,  92,   0,   0,  93,  94,  95,  96,   0,\n",
       "          0,  97,   0,  98,  99,   0, 100, 101,   0,   0,   0, 102,   0, 103,\n",
       "          0,   0,   0, 104,   0, 105,   0, 106, 107,   0,   0, 108, 109, 110,\n",
       "        111,   0, 112, 113, 114, 115,   0,   0, 116, 117, 118, 119,   0, 120,\n",
       "        121,   0,   0,   0, 122,   0, 123, 124, 125, 126,   0, 127, 128, 129,\n",
       "          0, 130, 131, 132, 133, 134, 135,   0,   0,   0, 136, 137, 138, 139,\n",
       "          0, 140,   0, 141, 142, 143,   0,   0, 144,   0, 145, 146, 147,   0,\n",
       "        148, 149,   0, 150, 151, 152, 153, 154,   0,   0, 155, 156,   0, 157,\n",
       "          0,   0, 158,   0,   0, 159, 160, 161,   0, 162,   0, 163, 164,   0,\n",
       "          0,   0,   0, 165, 166, 167, 168,   0,   0,   0,   0, 169, 170,   0,\n",
       "        171, 172, 173, 174,   0, 175,   0, 176, 177,   0, 178, 179, 180, 181,\n",
       "          0, 182,   0, 183, 184, 185, 186, 187, 188, 189,   0,   0, 190, 191,\n",
       "          0, 192, 193, 194, 195,   0,   0,   0, 196,   0,   0, 197,   0, 198,\n",
       "        199,   0,   0, 200,   0, 201,   0,   0,   0, 202,   0,   0,   0, 203,\n",
       "        204, 205,   0, 206, 207, 208, 209, 210, 211, 212, 213, 214,   0, 215,\n",
       "        216, 217, 218,   0, 219,   0, 220, 221, 222, 223,   0,   0, 224, 225,\n",
       "        226,   0, 227,   0, 228,   0,   0,   0,   0, 229, 230,   0, 231,   0,\n",
       "          0,   0, 232,   0, 233,   0,   0, 234,   0, 235, 236, 237, 238,   0,\n",
       "        239,   0, 240, 241,   0,   0,   0, 242, 243, 244,   0,   0,   0,   0,\n",
       "        245, 246,   0,   0,   0,   0,   0,   0, 247,   0, 248, 249, 250, 251,\n",
       "          0, 252, 253, 254, 255,   0, 256, 257,   0, 258,   0,   0, 259,   0,\n",
       "        260, 261, 262,   0, 263, 264,   0,   0,   0, 265, 266,   0,   0, 267,\n",
       "          0,   0, 268, 269,   0,   0, 270, 271, 272, 273, 274,   0, 275,   0,\n",
       "        276,   0, 277,   0, 278,   0,   0, 279, 280, 281,   0, 282, 283, 284,\n",
       "        285, 286, 287, 288, 289, 290,   0, 291, 292,   0, 293, 294, 295,   0,\n",
       "          0, 296, 297, 298, 299, 300,   0,   0, 301, 302, 303, 304, 305, 306,\n",
       "        307, 308, 309, 310, 311, 312, 313,   0, 314, 315, 316,   0, 317,   0,\n",
       "        318, 319, 320,   0,   0, 321,   0,   0,   0, 322,   0, 323, 324, 325,\n",
       "          0, 326,   0,   0,   0,   0,   0,   0,   0,   0, 327,   0, 328,   0,\n",
       "        329,   0,   0, 330, 331,   0,   0,   0, 332, 333,   0,   0, 334, 335,\n",
       "          0, 336,   0,   0,   0, 337,   0,   0, 338,   0,   0, 339, 340, 341,\n",
       "          0, 342,   0, 343,   0,   0, 344, 345,   0, 346, 347, 348, 349,   0,\n",
       "        350,   0, 351, 352, 353, 354, 355, 356,   0, 357, 358, 359,   0, 360,\n",
       "          0, 361, 362,   0,   0, 363, 364, 365, 366, 367,   0, 368,   0,   0,\n",
       "        369,   0, 370, 371,   0,   0,   0, 372, 373,   0,   0,   0, 374, 375,\n",
       "        376,   0, 377, 378, 379, 380, 381, 382,   0, 383, 384, 385, 386,   0,\n",
       "        387, 388, 389, 390, 391, 392,   0,   0,   0, 393, 394,   0, 395, 396,\n",
       "        397,   0, 398,   0,   0, 399,   0,   0, 400,   0, 401, 402, 403,   0,\n",
       "          0, 404, 405, 406, 407, 408, 409, 410, 411,   0,   0,   0, 412, 413,\n",
       "        414,   0, 415, 416, 417,   0,   0,   0, 418, 419, 420,   0,   0,   0,\n",
       "          0,   0,   0, 421, 422, 423, 424,   0, 425, 426, 427,   0,   0, 428,\n",
       "        429,   0,   0, 430, 431, 432, 433,   0,   0,   0,   0, 434, 435, 436,\n",
       "        437, 438, 439, 440, 441,   0, 442,   0, 443, 444, 445,   0, 446, 447,\n",
       "        448,   0,   0, 449,   0,   0, 450,   0, 451, 452, 453, 454,   0, 455,\n",
       "          0, 456,   0, 457,   0,   0,   0, 458, 459, 460, 461, 462, 463, 464,\n",
       "        465, 466, 467, 468,   0, 469, 470, 471,   0, 472, 473,   0, 474,   0,\n",
       "        475, 476,   0, 477, 478, 479,   0, 480,   0, 481, 482, 483, 484,   0,\n",
       "          0, 485, 486,   0,   0,   0, 487,   0, 488,   0,   0, 489, 490, 491,\n",
       "          0, 492, 493,   0, 494, 495, 496, 497, 498, 499,   0, 500, 501,   0,\n",
       "        502, 503,   0, 504, 505, 506, 507,   0,   0, 508,   0, 509, 510,   0,\n",
       "          0,   0, 511, 512, 513,   0, 514, 515, 516,   0, 517, 518, 519, 520,\n",
       "        521,   0, 522,   0,   0,   0, 523, 524,   0,   0, 525, 526, 527, 528,\n",
       "          0, 529,   0, 530,   0,   0,   0,   0, 531, 532, 533, 534, 535, 536,\n",
       "        537, 538, 539,   0, 540, 541, 542,   0, 543, 544, 545, 546,   0, 547,\n",
       "          0,   0,   0, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "        559,   0, 560, 561,   0, 562, 563,   0,   0,   0, 564,   0, 565, 566,\n",
       "          0,   0, 567, 568, 569, 570, 571, 572, 573, 574,   0, 575,   0,   0,\n",
       "        576,   0, 577, 578, 579, 580, 581,   0,   0, 582, 583, 584, 585,   0,\n",
       "        586, 587, 588, 589,   0, 590, 591, 592,   0,   0,   0,   0,   0, 593,\n",
       "        594, 595, 596,   0,   0,   0, 597, 598, 599, 600, 601, 602,   0,   0,\n",
       "        603,   0, 604, 605, 606,   0, 607, 608,   0, 609, 610,   0, 611, 612,\n",
       "        613, 614,   0,   0, 615, 616, 617, 618,   0,   0,   0, 619, 620, 621,\n",
       "        622,   0,   0, 623,   0,   0])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(999, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_nhood_lookup.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(997, device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_lookup.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_lookup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 2, 1,\n",
       "        1, 1, 4], device='cuda:0')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[reverse_lookup[cell_nhood_lookup[0].long()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47, device='cuda:0')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[reverse_lookup[cell_nhood_lookup.long()]].sum(1).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ This is the maximum choice of K ^^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
