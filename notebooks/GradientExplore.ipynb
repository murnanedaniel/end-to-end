{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to explore how gradients can be preserved on and off a GPU, accumulated *within* a batch, and be handled by multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from torch import optim\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Most Minimal Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- `retain_graph` allows multiple backward passes\n",
    "- The grad's are accumulated *on the leaf variables*\n",
    "- `backward` is run on an output variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.rand(4, requires_grad=True)\n",
    "y = torch.rand(4, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4820, 0.1776, 0.9892, 0.9979], requires_grad=True),\n",
       " tensor([0.5668, 0.8687, 0.2601, 0.8752], requires_grad=True))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z.backward(torch.FloatTensor([1.0, 1.0, 1.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1336, 1.7374, 0.5203, 1.7504])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9639, 0.3551, 1.9784, 1.9958])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## GPU on-and-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1_cpu = torch.tensor([1., 1., 1., 1.], requires_grad=True)\n",
    "y1_cpu = torch.tensor([4., 4., 4., 4.], requires_grad=True)\n",
    "x2_cpu = torch.tensor([1., 1., 1., 1.], requires_grad=True)\n",
    "y2_cpu = torch.tensor([3., 3., 3., 3.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1_cuda, y1_cuda = x1_cpu.to(\"cuda\"), y1_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cuda = x1_cuda * y1_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cpu = z1_cuda.to(\"cpu\")\n",
    "x1_cpu2, y1_cpu2 = x1_cuda.to(\"cpu\"), y1_cuda.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x2_cuda, y2_cuda = x2_cpu.to(\"cuda\"), y2_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z2_cuda = x2_cuda * y2_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cuda2 = z1_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z_total = z1_cuda2 + z2_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del x1_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z_total.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 4., 4.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_cpu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_cpu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3., 3.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_cpu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_cpu.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Memory Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/cuda/memory.py:234: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n",
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/torch/cuda/memory.py:260: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1_size = (100000,1000)\n",
    "y1_size = (100000,1000)\n",
    "x1 = torch.rand(x1_size, requires_grad=True, device=\"cuda\")\n",
    "y1 = torch.rand(y1_size, requires_grad=True, device=\"cuda\")\n",
    "x2 = torch.rand(x1_size, requires_grad=True, device=\"cuda\")\n",
    "y2 = torch.rand(y1_size, requires_grad=True, device=\"cuda\")\n",
    "# x1 = torch.rand(x1_size, device=\"cuda\")\n",
    "# y1 = torch.rand(y1_size, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.865234375\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z = x1*y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.865234375\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1 = x1.to(\"cpu\")\n",
    "y1 = y1.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.865234375\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6113290786743164\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "del z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23828125\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1.grad=None\n",
    "y1.grad=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated()\n",
    "torch.cuda.reset_max_memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.865234375\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.max_memory_allocated()/ 1024**3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x1_cuda, y1_cuda = x1_cpu.to(\"cuda\"), y1_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cuda = x1_cuda * y1_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cpu = z1_cuda.to(\"cpu\")\n",
    "x1_cpu2, y1_cpu2 = x1_cuda.to(\"cpu\"), y1_cuda.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x2_cuda, y2_cuda = x2_cpu.to(\"cuda\"), y2_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z2_cuda = x2_cuda * y2_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z1_cuda2 = z1_cpu.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "z_total = z1_cuda2 + z2_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Sequential Model Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We create a sequential NN, then feed a variable through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.add_module('W0', nn.Linear(3, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn((1,3), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0646,  0.7194, -0.4448]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1016]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W0.weight': Parameter containing:\n",
       " tensor([[ 0.2392,  0.3530, -0.0977],\n",
       "         [ 0.1958, -0.0073,  0.2408],\n",
       "         [ 0.0658,  0.4778,  0.1292],\n",
       "         [ 0.1938, -0.3796,  0.1065],\n",
       "         [-0.1575,  0.2916,  0.3924],\n",
       "         [-0.2167, -0.0704, -0.5197],\n",
       "         [ 0.4216,  0.1047,  0.5400],\n",
       "         [-0.4827,  0.4868, -0.5655],\n",
       "         [ 0.3096, -0.3725, -0.3382],\n",
       "         [ 0.0190, -0.3260, -0.0828],\n",
       "         [-0.1678,  0.4821,  0.1528],\n",
       "         [ 0.3671,  0.4760, -0.5092],\n",
       "         [ 0.2448,  0.2161, -0.1691],\n",
       "         [-0.4507,  0.2656,  0.4777],\n",
       "         [-0.1823, -0.2169,  0.4688],\n",
       "         [-0.2667,  0.5446,  0.2151]], requires_grad=True),\n",
       " 'W0.bias': Parameter containing:\n",
       " tensor([ 0.2466, -0.5018,  0.0103,  0.1711,  0.4140, -0.0998,  0.3709, -0.3463,\n",
       "          0.4880,  0.1452,  0.3080,  0.0793, -0.5400,  0.1486,  0.2751,  0.0492],\n",
       "        requires_grad=True),\n",
       " 'W1.weight': Parameter containing:\n",
       " tensor([[-0.1382,  0.0121,  0.1774,  0.1123, -0.0276,  0.1617,  0.0063,  0.2020,\n",
       "           0.0990, -0.1007, -0.1776, -0.0974, -0.1946, -0.1905, -0.0448,  0.1873]],\n",
       "        requires_grad=True),\n",
       " 'W1.bias': Parameter containing:\n",
       " tensor([-0.0114], requires_grad=True)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can backprop with a scalar (e.g. mean of y) and check that each variable accumulated a gradient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0893,  0.0204, -0.1982]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('W0.weight', Parameter containing:\n",
       "tensor([[ 0.2392,  0.3530, -0.0977],\n",
       "        [ 0.1958, -0.0073,  0.2408],\n",
       "        [ 0.0658,  0.4778,  0.1292],\n",
       "        [ 0.1938, -0.3796,  0.1065],\n",
       "        [-0.1575,  0.2916,  0.3924],\n",
       "        [-0.2167, -0.0704, -0.5197],\n",
       "        [ 0.4216,  0.1047,  0.5400],\n",
       "        [-0.4827,  0.4868, -0.5655],\n",
       "        [ 0.3096, -0.3725, -0.3382],\n",
       "        [ 0.0190, -0.3260, -0.0828],\n",
       "        [-0.1678,  0.4821,  0.1528],\n",
       "        [ 0.3671,  0.4760, -0.5092],\n",
       "        [ 0.2448,  0.2161, -0.1691],\n",
       "        [-0.4507,  0.2656,  0.4777],\n",
       "        [-0.1823, -0.2169,  0.4688],\n",
       "        [-0.2667,  0.5446,  0.2151]], requires_grad=True)), ('W0.bias', Parameter containing:\n",
       "tensor([ 0.2466, -0.5018,  0.0103,  0.1711,  0.4140, -0.0998,  0.3709, -0.3463,\n",
       "         0.4880,  0.1452,  0.3080,  0.0793, -0.5400,  0.1486,  0.2751,  0.0492],\n",
       "       requires_grad=True)), ('W1.weight', Parameter containing:\n",
       "tensor([[-0.1382,  0.0121,  0.1774,  0.1123, -0.0276,  0.1617,  0.0063,  0.2020,\n",
       "          0.0990, -0.1007, -0.1776, -0.0974, -0.1946, -0.1905, -0.0448,  0.1873]],\n",
       "       requires_grad=True)), ('W1.bias', Parameter containing:\n",
       "tensor([-0.0114], requires_grad=True))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters()).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0.weight tensor([[-0.0824, -0.0557,  0.0344],\n",
      "        [ 0.0110,  0.0074, -0.0046],\n",
      "        [ 0.1656,  0.1119, -0.0692],\n",
      "        [ 0.1192,  0.0806, -0.0498],\n",
      "        [-0.0272, -0.0183,  0.0113],\n",
      "        [ 0.1683,  0.1137, -0.0703],\n",
      "        [ 0.0045,  0.0030, -0.0019],\n",
      "        [ 0.2013,  0.1360, -0.0841],\n",
      "        [ 0.0669,  0.0452, -0.0279],\n",
      "        [-0.1071, -0.0724,  0.0447],\n",
      "        [-0.1608, -0.1086,  0.0672],\n",
      "        [-0.0410, -0.0277,  0.0171],\n",
      "        [-0.2067, -0.1397,  0.0864],\n",
      "        [-0.1796, -0.1213,  0.0750],\n",
      "        [-0.0441, -0.0298,  0.0184],\n",
      "        [ 0.1986,  0.1342, -0.0830]])\n",
      "W0.bias tensor([-0.0774,  0.0103,  0.1556,  0.1120, -0.0255,  0.1581,  0.0042,  0.1891,\n",
      "         0.0628, -0.1006, -0.1510, -0.0385, -0.1942, -0.1687, -0.0414,  0.1866])\n",
      "W1.weight tensor([[ 0.6633, -0.3848,  0.3510,  0.0568,  0.2743, -0.1488,  0.5750, -0.2529,\n",
      "          0.6044, -0.0322,  0.3869,  0.7775, -0.0487, -0.3388, -0.2762,  0.0613]])\n",
      "W1.bias tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in dict(model.named_parameters()).items():\n",
    "    print(k,v.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0.weight Parameter containing:\n",
      "tensor([[ 0.2392,  0.3530, -0.0977],\n",
      "        [ 0.1958, -0.0073,  0.2408],\n",
      "        [ 0.0658,  0.4778,  0.1292],\n",
      "        [ 0.1938, -0.3796,  0.1065],\n",
      "        [-0.1575,  0.2916,  0.3924],\n",
      "        [-0.2167, -0.0704, -0.5197],\n",
      "        [ 0.4216,  0.1047,  0.5400],\n",
      "        [-0.4827,  0.4868, -0.5655],\n",
      "        [ 0.3096, -0.3725, -0.3382],\n",
      "        [ 0.0190, -0.3260, -0.0828],\n",
      "        [-0.1678,  0.4821,  0.1528],\n",
      "        [ 0.3671,  0.4760, -0.5092],\n",
      "        [ 0.2448,  0.2161, -0.1691],\n",
      "        [-0.4507,  0.2656,  0.4777],\n",
      "        [-0.1823, -0.2169,  0.4688],\n",
      "        [-0.2667,  0.5446,  0.2151]], requires_grad=True)\n",
      "W0.bias Parameter containing:\n",
      "tensor([ 0.2466, -0.5018,  0.0103,  0.1711,  0.4140, -0.0998,  0.3709, -0.3463,\n",
      "         0.4880,  0.1452,  0.3080,  0.0793, -0.5400,  0.1486,  0.2751,  0.0492],\n",
      "       requires_grad=True)\n",
      "W1.weight Parameter containing:\n",
      "tensor([[-0.1382,  0.0121,  0.1774,  0.1123, -0.0276,  0.1617,  0.0063,  0.2020,\n",
      "          0.0990, -0.1007, -0.1776, -0.0974, -0.1946, -0.1905, -0.0448,  0.1873]],\n",
      "       requires_grad=True)\n",
      "W1.bias Parameter containing:\n",
      "tensor([-0.0114], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for (k, v) in dict(model.named_parameters()).items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu0 = \"cuda:0\"\n",
    "gpu1 = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_grads(model_A, model_B):\n",
    "    for layer_A, layer_B in zip(model_A.parameters(), model_B.parameters()):\n",
    "        device_A = layer_A.device\n",
    "        if layer_A.grad is None:\n",
    "            layer_A.grad = layer_B.grad/2\n",
    "        elif layer_B.grad is None:\n",
    "            layer_A.grad = layer_A.grad/2\n",
    "        else:\n",
    "            layer_A.grad = torch.mean(torch.stack([layer_A.grad, layer_B.grad.to(device_A)]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_layers(layer_A, layer_B, eps=1e-4):\n",
    "    return (layer_A.data - layer_B.data)/(layer_A.data + layer_B.data) < eps\n",
    "\n",
    "def compare_grads(layer_A, layer_B, eps=1e-4):\n",
    "    return (layer_A.grad - layer_B.grad)/(layer_A.grad + layer_B.grad) < eps\n",
    "\n",
    "def compare_models(model_A, model_B, eps=1e-4):\n",
    "    \n",
    "    equal_grads = True\n",
    "    \n",
    "    zipped_models = zip(model_A.parameters(), model_B.parameters())\n",
    "    compare_model_list = [compare_layers(layer_A, layer_B).all() for layer_A, layer_B in zipped_models]\n",
    "    equal_weights = torch.stack(compare_model_list).all()\n",
    "\n",
    "    if list(model_A.parameters())[0].grad is not None:\n",
    "        zipped_models = zip(model_A.parameters(), model_B.parameters())\n",
    "        compare_grad_list = [compare_grads(layer_A, layer_B).all() for layer_A, layer_B in zipped_models]\n",
    "        equal_grads = torch.stack(compare_grad_list).all()\n",
    "    \n",
    "    return equal_weights, equal_grads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_add_attention(encoded_nodes, encoded_edges, edge_list):\n",
    "    start, end = edge_list\n",
    "\n",
    "    src = encoded_nodes[end]*encoded_edges\n",
    "    index = start.unsqueeze(-1)\n",
    "    in_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "    src = encoded_nodes[start]*encoded_edges\n",
    "    index = end.unsqueeze(-1)\n",
    "    out_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "    \n",
    "    aggr_nodes = in_messages + out_messages\n",
    "    \n",
    "    return aggr_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single-GPU Toy A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.randint(0, 10, (10, 3)).float()\n",
    "M = torch.rand((3,3), requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,5],\n",
    "                  [2,3,2],\n",
    "                  [3,4,3],\n",
    "                  [4,4,4],\n",
    "                  [5,5,5],\n",
    "                  [9,5,2],\n",
    "                  [1,3,5],\n",
    "                  [2,5,7],\n",
    "                  [6,7,8],\n",
    "                  [1,2,3]], device=gpu0).float()\n",
    "M = torch.tensor([[0.1, 0.3, 0.5],\n",
    "                  [0.7, 0.9, 0.2],\n",
    "                  [0.4, 0.6, 0.8]], requires_grad=True, device=gpu0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = torch.matmul(x, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5000,  5.1000,  4.9000],\n",
       "        [ 3.1000,  4.5000,  3.2000],\n",
       "        [ 4.3000,  6.3000,  4.7000],\n",
       "        [ 4.8000,  7.2000,  6.0000],\n",
       "        [ 6.0000,  9.0000,  7.5000],\n",
       "        [ 5.2000,  8.4000,  7.1000],\n",
       "        [ 4.2000,  6.0000,  5.1000],\n",
       "        [ 6.5000,  9.3000,  7.6000],\n",
       "        [ 8.7000, 12.9000, 10.8000],\n",
       "        [ 2.7000,  3.9000,  3.3000]], device='cuda:0', grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.1800, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4000, 3.4000, 3.4000],\n",
       "        [4.0000, 4.0000, 4.0000],\n",
       "        [4.4000, 4.4000, 4.4000]], device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.5000],\n",
       "        [0.7000, 0.9000, 0.2000],\n",
       "        [0.4000, 0.6000, 0.8000]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-GPU Toy A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,5],\n",
    "                  [2,3,2],\n",
    "                  [3,4,3],\n",
    "                  [4,4,4],\n",
    "                  [5,5,5],\n",
    "                  [9,5,2],\n",
    "                  [1,3,5],\n",
    "                  [2,5,7],\n",
    "                  [6,7,8],\n",
    "                  [1,2,3]], device=gpu0).float()\n",
    "M = torch.tensor([[0.1, 0.3, 0.5],\n",
    "                  [0.7, 0.9, 0.2],\n",
    "                  [0.4, 0.6, 0.8]], requires_grad=True, device=gpu0).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = x[:5].to(gpu0)\n",
    "x1 = x[5:].to(gpu1)\n",
    "M1 = M.to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = torch.matmul(x0, M)\n",
    "output1 = torch.matmul(x1, M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.5000, 5.1000, 4.9000],\n",
       "         [3.1000, 4.5000, 3.2000],\n",
       "         [4.3000, 6.3000, 4.7000],\n",
       "         [4.8000, 7.2000, 6.0000],\n",
       "         [6.0000, 9.0000, 7.5000]], device='cuda:0', grad_fn=<MmBackward>),\n",
       " tensor([[ 5.2000,  8.4000,  7.1000],\n",
       "         [ 4.2000,  6.0000,  5.1000],\n",
       "         [ 6.5000,  9.3000,  7.6000],\n",
       "         [ 8.7000, 12.9000, 10.8000],\n",
       "         [ 2.7000,  3.9000,  3.3000]], device='cuda:1', grad_fn=<MmBackward>))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0, output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.sum(axis=1).mean()\n",
    "loss1 = output1.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(16.0200, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(20.3400, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 3.0000, 3.0000],\n",
       "        [3.6000, 3.6000, 3.6000],\n",
       "        [3.8000, 3.8000, 3.8000]], device='cuda:0')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss1 = loss1.to(gpu0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_total = torch.cat([loss0.unsqueeze(0), loss1.unsqueeze(0)]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.1800, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_total.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.4000, 3.4000, 3.4000],\n",
       "        [4.0000, 4.0000, 4.0000],\n",
       "        [4.4000, 4.4000, 4.4000]], device='cuda:0')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.5000],\n",
       "        [0.7000, 0.9000, 0.2000],\n",
       "        [0.4000, 0.6000, 0.8000]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "M1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.3000, 0.5000],\n",
       "        [0.7000, 0.9000, 0.2000],\n",
       "        [0.4000, 0.6000, 0.8000]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single-GPU Toy B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x = torch.tensor([[1,2,5],\n",
    "#                   [2,3,2],\n",
    "#                   [3,4,3],\n",
    "#                   [4,4,4],\n",
    "#                   [5,5,5],\n",
    "#                   [9,5,2],\n",
    "#                   [1,3,5],\n",
    "#                   [2,5,7],\n",
    "#                   [6,7,8],\n",
    "#                   [1,2,3]], device=gpu0).float()\n",
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(3, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))\n",
    "model = model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1914,  0.1616,  0.1033],\n",
       "        [-0.0220, -0.0157, -0.0333],\n",
       "        [ 0.0085,  0.0041,  0.0098],\n",
       "        [ 0.1084,  0.0936,  0.1036],\n",
       "        [ 0.0247,  0.0124,  0.0441],\n",
       "        [ 0.2035,  0.1286,  0.1052],\n",
       "        [-0.2375, -0.1711, -0.2726],\n",
       "        [-0.0571, -0.0499, -0.0299],\n",
       "        [ 0.1281,  0.0958,  0.0452],\n",
       "        [ 0.0136,  0.0068,  0.0327],\n",
       "        [ 0.2939,  0.2770,  0.1683],\n",
       "        [ 0.0220,  0.0107,  0.0102],\n",
       "        [ 0.0668,  0.0362,  0.0384],\n",
       "        [-0.3333, -0.2625, -0.3525],\n",
       "        [ 0.0095,  0.0038,  0.0047],\n",
       "        [-0.2360, -0.1438, -0.1185]], device='cuda:0')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_gpu_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0062,  0.3081, -0.4762],\n",
       "        [-0.4247, -0.2222,  0.1552],\n",
       "        [-0.0115,  0.4577, -0.0513],\n",
       "        [ 0.1517, -0.1754, -0.1145],\n",
       "        [-0.5518, -0.3825, -0.2384],\n",
       "        [ 0.0194,  0.2270,  0.3454],\n",
       "        [-0.3890, -0.2497,  0.2124],\n",
       "        [ 0.4800, -0.1183,  0.4323],\n",
       "        [-0.0943,  0.0601,  0.5223],\n",
       "        [-0.5357, -0.3635, -0.1465],\n",
       "        [-0.2280,  0.4961, -0.3759],\n",
       "        [-0.2660, -0.4035, -0.5408],\n",
       "        [-0.3377,  0.4959,  0.2572],\n",
       "        [ 0.2832,  0.0330, -0.2925],\n",
       "        [ 0.0976, -0.5391, -0.4172],\n",
       "        [-0.2953,  0.3657,  0.3397]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-GPU Toy B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,2,5],\n",
    "                  [2,3,2],\n",
    "                  [3,4,3],\n",
    "                  [4,4,4],\n",
    "                  [5,5,5],\n",
    "                  [9,5,2],\n",
    "                  [1,3,5],\n",
    "                  [2,5,7],\n",
    "                  [6,7,8],\n",
    "                  [1,2,3]], device=gpu0).float()\n",
    "torch.random.manual_seed(0)\n",
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(3, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))\n",
    "model = model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W0.weight': Parameter containing:\n",
       " tensor([[-0.0043,  0.3097, -0.4752],\n",
       "         [-0.4249, -0.2224,  0.1548],\n",
       "         [-0.0114,  0.4578, -0.0512],\n",
       "         [ 0.1528, -0.1745, -0.1135],\n",
       "         [-0.5516, -0.3824, -0.2380],\n",
       "         [ 0.0214,  0.2282,  0.3464],\n",
       "         [-0.3914, -0.2514,  0.2097],\n",
       "         [ 0.4794, -0.1188,  0.4320],\n",
       "         [-0.0931,  0.0611,  0.5228],\n",
       "         [-0.5356, -0.3635, -0.1462],\n",
       "         [-0.2251,  0.4988, -0.3742],\n",
       "         [-0.2658, -0.4034, -0.5407],\n",
       "         [-0.3370,  0.4963,  0.2576],\n",
       "         [ 0.2798,  0.0304, -0.2960],\n",
       "         [ 0.0977, -0.5391, -0.4172],\n",
       "         [-0.2976,  0.3643,  0.3385]], device='cuda:0', requires_grad=True),\n",
       " 'W0.bias': Parameter containing:\n",
       " tensor([-0.2561, -0.0208,  0.3693,  0.5740,  0.2291,  0.0780,  0.3871, -0.3399,\n",
       "          0.1076, -0.4476, -0.4002, -0.2982,  0.2612,  0.2322, -0.3420,  0.1744],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'W1.weight': Parameter containing:\n",
       " tensor([[ 0.1372, -0.0316,  0.0095,  0.0579,  0.1551,  0.2400, -0.1927, -0.0916,\n",
       "           0.0983,  0.2071,  0.2176,  0.2206,  0.0498, -0.2174,  0.0230, -0.1564]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'W1.bias': Parameter containing:\n",
       " tensor([-0.2330], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = x[:5].to(gpu0)\n",
    "x1 = x[5:].to(gpu1)\n",
    "model1 = deepcopy(model).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = model(x0)\n",
    "output1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9610],\n",
       "         [-0.6608],\n",
       "         [-0.6709],\n",
       "         [-0.7950],\n",
       "         [-0.8115]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.6590],\n",
       "         [-0.8913],\n",
       "         [-0.7894],\n",
       "         [-0.7682],\n",
       "         [-0.8659]], device='cuda:1', grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0, output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.7798, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-0.7948, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss1 = loss1.to(gpu0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_total = torch.cat([loss0.unsqueeze(0), loss1.unsqueeze(0)]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7873, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_total.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0979e-01,  1.3462e-01,  1.1355e-01],\n",
       "         [-7.4301e-03, -1.1841e-02, -1.9882e-02],\n",
       "         [ 1.3359e-03,  1.9314e-03,  2.8978e-03],\n",
       "         [ 8.6169e-02,  1.0325e-01,  1.0853e-01],\n",
       "         [ 1.6269e-03,  2.7213e-03,  4.1838e-03],\n",
       "         [ 1.7714e-02,  2.4446e-02,  2.1588e-02],\n",
       "         [-8.5569e-02, -1.1815e-01, -1.4382e-01],\n",
       "         [-9.7857e-03, -1.4269e-02, -1.2082e-02],\n",
       "         [ 1.4356e-02,  1.9139e-02,  1.4992e-02],\n",
       "         [ 1.2452e-03,  2.1435e-03,  3.7204e-03],\n",
       "         [ 2.1096e-01,  2.5732e-01,  2.2673e-01],\n",
       "         [ 4.2664e-04,  6.3832e-04,  5.2862e-04],\n",
       "         [ 5.3049e-03,  6.6481e-03,  6.2496e-03],\n",
       "         [-2.8935e-01, -3.3966e-01, -3.3125e-01],\n",
       "         [ 1.6181e-04,  2.3137e-04,  2.0203e-04],\n",
       "         [-2.3601e-02, -2.9684e-02, -2.6077e-02]], device='cuda:0'),\n",
       " tensor([[ 1.2834e-01,  9.0607e-02,  6.4513e-02],\n",
       "         [-8.7872e-03, -2.1724e-02, -3.3122e-02],\n",
       "         [ 8.8898e-04,  1.5966e-03,  2.2927e-03],\n",
       "         [ 6.8412e-02,  8.6089e-02,  1.0350e-01],\n",
       "         [ 1.9208e-03,  4.1503e-03,  6.3714e-03],\n",
       "         [ 1.6913e-02,  1.6445e-02,  1.7302e-02],\n",
       "         [-8.1710e-02, -1.9316e-01, -2.8602e-01],\n",
       "         [-3.7650e-03, -8.2301e-03, -1.2621e-02],\n",
       "         [ 6.2944e-02,  3.7170e-02,  1.8213e-02],\n",
       "         [ 1.4263e-03,  3.1670e-03,  4.8942e-03],\n",
       "         [ 2.0482e-01,  2.1401e-01,  2.2786e-01],\n",
       "         [ 2.3987e-04,  4.8050e-04,  7.2181e-04],\n",
       "         [ 4.3394e-02,  2.5313e-02,  1.1955e-02],\n",
       "         [-1.7608e-01, -2.5719e-01, -3.3168e-01],\n",
       "         [ 2.6376e-04,  2.3163e-04,  2.2243e-04],\n",
       "         [-1.4364e-01, -8.4097e-02, -4.0157e-02]], device='cuda:1'))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"].grad, dict(model1.named_parameters())[\"W0.weight\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"].grad = dict(model.named_parameters())[\"W0.weight\"].grad + dict(model1.named_parameters())[\"W0.weight\"].grad.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0043,  0.3097, -0.4752],\n",
       "         [-0.4249, -0.2224,  0.1548],\n",
       "         [-0.0114,  0.4578, -0.0512],\n",
       "         [ 0.1528, -0.1745, -0.1135],\n",
       "         [-0.5516, -0.3824, -0.2380],\n",
       "         [ 0.0214,  0.2282,  0.3464],\n",
       "         [-0.3914, -0.2514,  0.2097],\n",
       "         [ 0.4794, -0.1188,  0.4320],\n",
       "         [-0.0931,  0.0611,  0.5228],\n",
       "         [-0.5356, -0.3635, -0.1462],\n",
       "         [-0.2251,  0.4988, -0.3742],\n",
       "         [-0.2658, -0.4034, -0.5407],\n",
       "         [-0.3370,  0.4963,  0.2576],\n",
       "         [ 0.2798,  0.0304, -0.2960],\n",
       "         [ 0.0977, -0.5391, -0.4172],\n",
       "         [-0.2976,  0.3643,  0.3385]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0043,  0.3097, -0.4752],\n",
       "         [-0.4249, -0.2224,  0.1548],\n",
       "         [-0.0114,  0.4578, -0.0512],\n",
       "         [ 0.1528, -0.1745, -0.1135],\n",
       "         [-0.5516, -0.3824, -0.2380],\n",
       "         [ 0.0214,  0.2282,  0.3464],\n",
       "         [-0.3914, -0.2514,  0.2097],\n",
       "         [ 0.4794, -0.1188,  0.4320],\n",
       "         [-0.0931,  0.0611,  0.5228],\n",
       "         [-0.5356, -0.3635, -0.1462],\n",
       "         [-0.2251,  0.4988, -0.3742],\n",
       "         [-0.2658, -0.4034, -0.5407],\n",
       "         [-0.3370,  0.4963,  0.2576],\n",
       "         [ 0.2798,  0.0304, -0.2960],\n",
       "         [ 0.0977, -0.5391, -0.4172],\n",
       "         [-0.2976,  0.3643,  0.3385]], device='cuda:1', requires_grad=True))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"], dict(model1.named_parameters())[\"W0.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0067,  0.3075, -0.4770],\n",
       "        [-0.4247, -0.2220,  0.1554],\n",
       "        [-0.0115,  0.4577, -0.0513],\n",
       "        [ 0.1512, -0.1764, -0.1156],\n",
       "        [-0.5516, -0.3824, -0.2381],\n",
       "        [ 0.0210,  0.2278,  0.3460],\n",
       "        [-0.3897, -0.2483,  0.2140],\n",
       "        [ 0.4796, -0.1186,  0.4323],\n",
       "        [-0.0938,  0.0605,  0.5224],\n",
       "        [-0.5356, -0.3635, -0.1463],\n",
       "        [-0.2292,  0.4941, -0.3788],\n",
       "        [-0.2658, -0.4034, -0.5407],\n",
       "        [-0.3375,  0.4960,  0.2574],\n",
       "        [ 0.2845,  0.0363, -0.2894],\n",
       "        [ 0.0977, -0.5391, -0.4172],\n",
       "        [-0.2960,  0.3654,  0.3392]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-GPU Toy B (Alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# x = torch.tensor([[1,2,5],\n",
    "#                   [2,3,2],\n",
    "#                   [3,4,3],\n",
    "#                   [4,4,4],\n",
    "#                   [5,5,5],\n",
    "#                   [9,5,2],\n",
    "#                   [1,3,5],\n",
    "#                   [2,5,7],\n",
    "#                   [6,7,8],\n",
    "#                   [1,2,3]], device=gpu0).float()\n",
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(3, 16))\n",
    "model.add_module('tanh', nn.Tanh())\n",
    "model.add_module('W1', nn.Linear(16, 1))\n",
    "model = model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = x[:len(x)//2].to(gpu0)\n",
    "x1 = x[len(x)//2:].to(gpu1)\n",
    "model1 = deepcopy(model).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = model(x0)\n",
    "output1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6488],\n",
       "         [-0.8170],\n",
       "         [-0.7162],\n",
       "         [-0.9621],\n",
       "         [-0.6709],\n",
       "         [-0.4777],\n",
       "         [-0.9215],\n",
       "         [-0.7507],\n",
       "         [-0.7782],\n",
       "         [-0.9010]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.9491],\n",
       "         [-0.9512],\n",
       "         [-0.9010],\n",
       "         [-0.9053],\n",
       "         [-0.9539],\n",
       "         [-0.9902],\n",
       "         [-0.5192],\n",
       "         [-0.6586],\n",
       "         [-0.8127],\n",
       "         [-0.4590]], device='cuda:1', grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0, output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.7644, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-0.8100, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0.backward()\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(model, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1914,  0.1616,  0.1033],\n",
       "        [-0.0220, -0.0157, -0.0333],\n",
       "        [ 0.0085,  0.0041,  0.0098],\n",
       "        [ 0.1084,  0.0936,  0.1036],\n",
       "        [ 0.0247,  0.0124,  0.0441],\n",
       "        [ 0.2035,  0.1286,  0.1052],\n",
       "        [-0.2375, -0.1711, -0.2726],\n",
       "        [-0.0571, -0.0499, -0.0299],\n",
       "        [ 0.1281,  0.0958,  0.0452],\n",
       "        [ 0.0136,  0.0068,  0.0327],\n",
       "        [ 0.2939,  0.2770,  0.1683],\n",
       "        [ 0.0220,  0.0107,  0.0102],\n",
       "        [ 0.0668,  0.0362,  0.0384],\n",
       "        [-0.3333, -0.2625, -0.3525],\n",
       "        [ 0.0095,  0.0038,  0.0047],\n",
       "        [-0.2360, -0.1438, -0.1185]], device='cuda:0')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gpu_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'),\n",
       " [tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0')])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_model, multi_gpu_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single-GPU Toy C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 10), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model = nn.Sequential()\n",
    "encoder_model.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model.add_module('tanh', nn.Tanh())\n",
    "encoder_model.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model = encoder_model.to(gpu0)\n",
    "\n",
    "class_model = nn.Sequential()\n",
    "class_model.add_module('W0', nn.Linear(3, 16))\n",
    "class_model.add_module('tanh', nn.Tanh())\n",
    "class_model.add_module('W1', nn.Linear(16, 1))\n",
    "class_model = class_model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model.parameters()) + list(class_model.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes = encoder_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e\n",
    "\n",
    "src = encoded_nodes[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = class_model(aggr_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0448],\n",
       "        [ 0.3763],\n",
       "        [-0.3279],\n",
       "        [ 0.1582],\n",
       "        [ 0.2266],\n",
       "        [ 0.2254],\n",
       "        [-0.3279],\n",
       "        [-0.3279],\n",
       "        [-0.3279],\n",
       "        [ 0.1102],\n",
       "        [ 0.3028],\n",
       "        [-0.3279],\n",
       "        [-0.0107],\n",
       "        [-0.0013],\n",
       "        [-0.1709],\n",
       "        [-0.0309],\n",
       "        [-0.3279],\n",
       "        [-0.3279],\n",
       "        [-0.3279],\n",
       "        [-0.3279]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0905, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7717e-02, -4.0987e-02, -3.3916e-02],\n",
       "        [ 4.3297e-03,  1.3792e-03,  9.3630e-03],\n",
       "        [ 1.1613e-02,  3.9398e-03,  2.1406e-02],\n",
       "        [-1.4218e-02, -1.0726e-02, -1.5382e-02],\n",
       "        [-4.3082e-03, -2.2294e-03, -2.5488e-02],\n",
       "        [-2.7659e-02, -1.5260e-02, -3.3299e-02],\n",
       "        [ 6.4564e-02,  5.3853e-02,  1.0259e-01],\n",
       "        [ 6.5279e-03,  7.9564e-03,  9.4455e-03],\n",
       "        [-3.9221e-03, -3.7380e-03, -2.5951e-03],\n",
       "        [-2.1158e-03, -8.6539e-04, -1.5249e-02],\n",
       "        [-3.3486e-02, -4.2239e-02, -3.6859e-02],\n",
       "        [-9.4915e-04, -3.4031e-04, -1.6120e-03],\n",
       "        [-4.0669e-03, -2.0772e-03, -5.5126e-03],\n",
       "        [ 7.7644e-02,  6.7564e-02,  1.1117e-01],\n",
       "        [-1.4008e-03, -4.8877e-05, -1.2799e-03],\n",
       "        [ 1.9433e-02,  9.7203e-03,  1.9479e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(encoder_model.named_parameters())[\"W0.weight\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_gpu_encoder_model = deepcopy(encoder_model)\n",
    "single_gpu_class_model = deepcopy(class_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2097,  0.4794, -0.1188],\n",
       "        [ 0.4320, -0.0931,  0.0611],\n",
       "        [ 0.5228, -0.5356, -0.3635],\n",
       "        [-0.1462, -0.2251,  0.4988],\n",
       "        [-0.3742, -0.2658, -0.4034],\n",
       "        [-0.5407, -0.3370,  0.4963],\n",
       "        [ 0.2576,  0.2798,  0.0304],\n",
       "        [-0.2960,  0.0977, -0.5391],\n",
       "        [-0.4172, -0.2976,  0.3643],\n",
       "        [ 0.3385, -0.2561, -0.0208],\n",
       "        [ 0.3693,  0.5740,  0.2291],\n",
       "        [ 0.0780,  0.3871, -0.3399],\n",
       "        [ 0.1076, -0.4476, -0.4002],\n",
       "        [-0.2982,  0.2612,  0.2322],\n",
       "        [-0.3420,  0.1744,  0.3169],\n",
       "        [-0.0729,  0.0220,  0.1338]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())[\"W0.weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-GPU Toy C (Alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 10), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model = nn.Sequential()\n",
    "encoder_model.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model.add_module('tanh', nn.Tanh())\n",
    "encoder_model.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model = encoder_model.to(gpu0)\n",
    "\n",
    "class_model = nn.Sequential()\n",
    "class_model.add_module('W0', nn.Linear(3, 16))\n",
    "class_model.add_module('tanh', nn.Tanh())\n",
    "class_model.add_module('W1', nn.Linear(16, 1))\n",
    "class_model = class_model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model.parameters()) + list(class_model.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e0 = e[:, :e.shape[1]//2].to(gpu0)\n",
    "e1 = e[:, e.shape[1]//2:].to(gpu1)\n",
    "x1 = x.to(gpu1)\n",
    "encoder_model1 = deepcopy(encoder_model).to(gpu1)\n",
    "class_model1 = deepcopy(class_model).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes0 = encoder_model(x)\n",
    "encoded_nodes1 = encoder_model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_nodes0 == encoded_nodes1.to(gpu0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e0\n",
    "\n",
    "src = encoded_nodes0[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes0.shape, dtype=src.dtype, device=encoded_nodes0.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes0[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes0.shape, dtype=src.dtype, device=encoded_nodes0.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes0 = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e1\n",
    "\n",
    "src = encoded_nodes1[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes1.shape, dtype=src.dtype, device=encoded_nodes1.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes1[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes1.shape, dtype=src.dtype, device=encoded_nodes1.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes1 = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aggr_nodes0 == aggr_nodes).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes_total0 = aggr_nodes0 + aggr_nodes1.to(aggr_nodes0.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes_total1 = aggr_nodes_total0.to(gpu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aggr_nodes_total0 == aggr_nodes).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = class_model(aggr_nodes_total0)\n",
    "output1 = class_model1(aggr_nodes_total1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0905, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0905, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0.backward(retain_graph=True)\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(encoder_model, encoder_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(class_model, class_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7717e-02, -4.0987e-02, -3.3916e-02],\n",
       "        [ 4.3297e-03,  1.3792e-03,  9.3630e-03],\n",
       "        [ 1.1613e-02,  3.9398e-03,  2.1406e-02],\n",
       "        [-1.4218e-02, -1.0726e-02, -1.5382e-02],\n",
       "        [-4.3082e-03, -2.2294e-03, -2.5488e-02],\n",
       "        [-2.7659e-02, -1.5260e-02, -3.3299e-02],\n",
       "        [ 6.4564e-02,  5.3853e-02,  1.0259e-01],\n",
       "        [ 6.5279e-03,  7.9564e-03,  9.4455e-03],\n",
       "        [-3.9221e-03, -3.7380e-03, -2.5951e-03],\n",
       "        [-2.1158e-03, -8.6539e-04, -1.5249e-02],\n",
       "        [-3.3486e-02, -4.2239e-02, -3.6859e-02],\n",
       "        [-9.4915e-04, -3.4031e-04, -1.6120e-03],\n",
       "        [-4.0669e-03, -2.0772e-03, -5.5126e-03],\n",
       "        [ 7.7644e-02,  6.7564e-02,  1.1117e-01],\n",
       "        [-1.4008e-03, -4.8877e-05, -1.2799e-03],\n",
       "        [ 1.9433e-02,  9.7203e-03,  1.9479e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder_model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gpu_encoder_model = deepcopy(encoder_model)\n",
    "multi_gpu_class_model = deepcopy(class_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'),\n",
       " [tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0')])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_encoder_model, multi_gpu_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'),\n",
       " [tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0')])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_class_model, multi_gpu_class_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single-GPU Toy D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 10), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model = nn.Sequential()\n",
    "encoder_model.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model.add_module('tanh', nn.Tanh())\n",
    "encoder_model.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model = encoder_model.to(gpu0)\n",
    "\n",
    "class_model = nn.Sequential()\n",
    "class_model.add_module('W0', nn.Linear(6, 16))\n",
    "class_model.add_module('tanh', nn.Tanh())\n",
    "class_model.add_module('W1', nn.Linear(16, 1))\n",
    "class_model = class_model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model.parameters()) + list(class_model.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes = encoder_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e\n",
    "\n",
    "src = encoded_nodes[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_edges = torch.cat([aggr_nodes[start], aggr_nodes[end]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = class_model(input_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0477, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0017, -0.0006,  0.0031],\n",
       "        [-0.0089, -0.0035, -0.0386],\n",
       "        [-0.0014,  0.0016,  0.0043],\n",
       "        [-0.0072, -0.0163,  0.0477],\n",
       "        [-0.0017, -0.0010, -0.0084],\n",
       "        [ 0.0053,  0.0023,  0.0062],\n",
       "        [-0.0121, -0.0122, -0.0169],\n",
       "        [-0.0004, -0.0010,  0.0021],\n",
       "        [ 0.0018,  0.0012,  0.0045],\n",
       "        [ 0.0016,  0.0008,  0.0152],\n",
       "        [ 0.0010,  0.0017,  0.0098],\n",
       "        [ 0.0007,  0.0004,  0.0017],\n",
       "        [-0.0008,  0.0012, -0.0046],\n",
       "        [-0.0114, -0.0063, -0.0419],\n",
       "        [ 0.0051,  0.0003,  0.0076],\n",
       "        [-0.0022, -0.0021, -0.0072]], device='cuda:0')"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder_model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_gpu_encoder_model = deepcopy(encoder_model)\n",
    "single_gpu_class_model = deepcopy(class_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3452, -0.1010,  0.0186,  0.0587,  0.0974,  0.1603],\n",
       "        [ 0.0230, -0.1982,  0.1934, -0.3929, -0.2412, -0.1020],\n",
       "        [-0.1995, -0.1424, -0.3345, -0.0874,  0.0876, -0.2659],\n",
       "        [-0.0209,  0.2922, -0.0420,  0.0114, -0.0352,  0.0826],\n",
       "        [ 0.2621,  0.3851,  0.2589,  0.3896, -0.0307, -0.3670],\n",
       "        [-0.1931,  0.2777, -0.0027, -0.2025, -0.3131, -0.3821],\n",
       "        [-0.3413, -0.0850,  0.2234,  0.2235, -0.3954,  0.2543],\n",
       "        [-0.3179, -0.0873, -0.1658, -0.0771, -0.0811, -0.3666],\n",
       "        [-0.3543, -0.0627,  0.0055, -0.1871,  0.1547, -0.3672],\n",
       "        [-0.0257,  0.3578, -0.1668,  0.3703,  0.1468, -0.3687],\n",
       "        [ 0.2570, -0.0463, -0.1821,  0.3253, -0.3293,  0.0440],\n",
       "        [-0.0868,  0.2924,  0.1142,  0.1948,  0.1450, -0.0980],\n",
       "        [-0.0849, -0.3371,  0.2211,  0.3250,  0.2788, -0.2881],\n",
       "        [ 0.0194, -0.2886, -0.2249, -0.2367,  0.1388, -0.2435],\n",
       "        [-0.0062,  0.0154,  0.2628, -0.3062, -0.2818, -0.2374],\n",
       "        [ 0.2853, -0.1465,  0.3444,  0.1471,  0.0520, -0.0030]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(class_model.named_parameters())[\"W0.weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Multi-GPU Toy D (Alternate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (20, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 10), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model0 = nn.Sequential()\n",
    "encoder_model0.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model0.add_module('tanh', nn.Tanh())\n",
    "encoder_model0.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model0 = encoder_model0.to(gpu0)\n",
    "\n",
    "class_model0 = nn.Sequential()\n",
    "class_model0.add_module('W0', nn.Linear(6, 16))\n",
    "class_model0.add_module('tanh', nn.Tanh())\n",
    "class_model0.add_module('W1', nn.Linear(16, 1))\n",
    "class_model0 = class_model0.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model0.parameters()) + list(class_model0.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e0 = e[:, :e.shape[1]//2].to(gpu0)\n",
    "e1 = e[:, e.shape[1]//2:].to(gpu1)\n",
    "x1 = x.to(gpu1)\n",
    "encoder_model1 = deepcopy(encoder_model0).to(gpu1)\n",
    "class_model1 = deepcopy(class_model0).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes0 = encoder_model0(x)\n",
    "encoded_nodes1 = encoder_model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_nodes0 == encoded_nodes1.to(gpu0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e0\n",
    "\n",
    "src = encoded_nodes0[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes0.shape, dtype=src.dtype, device=encoded_nodes0.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes0[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes0.shape, dtype=src.dtype, device=encoded_nodes0.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes0 = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start, end = e1\n",
    "\n",
    "src = encoded_nodes1[end]\n",
    "index = start.unsqueeze(-1)\n",
    "in_messages = torch.zeros(encoded_nodes1.shape, dtype=src.dtype, device=encoded_nodes1.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "src = encoded_nodes1[start]\n",
    "index = end.unsqueeze(-1)\n",
    "out_messages = torch.zeros(encoded_nodes1.shape, dtype=src.dtype, device=encoded_nodes1.device).scatter_add(0, index.repeat((1,src.shape[1])), src) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes1 = in_messages + out_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes_total0 = aggr_nodes0 + aggr_nodes1.to(aggr_nodes0.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aggr_nodes_total1 = aggr_nodes_total0.to(gpu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(aggr_nodes_total0 == aggr_nodes).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_edges0 = torch.cat([aggr_nodes_total0[e0[0]], aggr_nodes_total0[e0[1]]], axis=-1)\n",
    "input_edges1 = torch.cat([aggr_nodes_total1[e1[0]], aggr_nodes_total1[e1[1]]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = class_model0(input_edges0)\n",
    "output1 = class_model1(input_edges1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0223, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0731, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0477, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0.backward(retain_graph=True)\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(encoder_model0, encoder_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(class_model0, class_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0017, -0.0006,  0.0031],\n",
       "        [-0.0089, -0.0035, -0.0386],\n",
       "        [-0.0014,  0.0016,  0.0043],\n",
       "        [-0.0072, -0.0163,  0.0477],\n",
       "        [-0.0017, -0.0010, -0.0084],\n",
       "        [ 0.0053,  0.0023,  0.0062],\n",
       "        [-0.0121, -0.0122, -0.0169],\n",
       "        [-0.0004, -0.0010,  0.0021],\n",
       "        [ 0.0018,  0.0012,  0.0045],\n",
       "        [ 0.0016,  0.0008,  0.0152],\n",
       "        [ 0.0010,  0.0017,  0.0098],\n",
       "        [ 0.0007,  0.0004,  0.0017],\n",
       "        [-0.0008,  0.0012, -0.0046],\n",
       "        [-0.0114, -0.0063, -0.0419],\n",
       "        [ 0.0051,  0.0003,  0.0076],\n",
       "        [-0.0022, -0.0021, -0.0072]], device='cuda:0')"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoder_model0.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gpu_encoder_model = deepcopy(encoder_model0)\n",
    "multi_gpu_class_model = deepcopy(class_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'),\n",
       " [tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0')])"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_encoder_model, multi_gpu_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'),\n",
       " [tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0'),\n",
       "  tensor(True, device='cuda:0')])"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_class_model, multi_gpu_class_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Realistic Multi-GPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scatter_add_nodes(encoded_nodes, edge_list):\n",
    "    start, end = edge_list\n",
    "\n",
    "    src = encoded_nodes[end]\n",
    "    index = start.unsqueeze(-1)\n",
    "    in_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "\n",
    "    src = encoded_nodes[start]\n",
    "    index = end.unsqueeze(-1)\n",
    "    out_messages = torch.zeros(encoded_nodes.shape, dtype=src.dtype, device=encoded_nodes.device).scatter_add(0, index.repeat((1,src.shape[1])), src) \n",
    "    \n",
    "    aggr_nodes = in_messages + out_messages\n",
    "    \n",
    "    return aggr_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Single-GPU Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_graph_iters = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (10, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 100), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model = nn.Sequential()\n",
    "encoder_model.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model.add_module('tanh', nn.Tanh())\n",
    "encoder_model.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model = encoder_model.to(gpu0)\n",
    "\n",
    "node_model = nn.Sequential()\n",
    "node_model.add_module('W0', nn.Linear(3, 16))\n",
    "node_model.add_module('tanh', nn.Tanh())\n",
    "node_model.add_module('W1', nn.Linear(16, 3))\n",
    "node_model = node_model.to(gpu0)\n",
    "\n",
    "edge_model = nn.Sequential()\n",
    "edge_model.add_module('W0', nn.Linear(6, 16))\n",
    "edge_model.add_module('tanh', nn.Tanh())\n",
    "edge_model.add_module('W1', nn.Linear(16, 1))\n",
    "edge_model = edge_model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model.parameters()) + list(node_model.parameters()) + list(edge_model.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes = encoder_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_graph_iters):\n",
    "    scattered_nodes = scatter_add_nodes(encoded_nodes, e)\n",
    "    encoded_nodes = node_model(scattered_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_edges = torch.cat([encoded_nodes[e[0]], encoded_nodes[e[1]]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output = edge_model(input_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0632, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "single_gpu_encoder_model = deepcopy(encoder_model)\n",
    "single_gpu_node_model = deepcopy(node_model)\n",
    "single_gpu_edge_model = deepcopy(edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multi-GPU Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_graph_iters = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (10, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 100), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model0 = nn.Sequential()\n",
    "encoder_model0.add_module('W0', nn.Linear(3, 16))\n",
    "encoder_model0.add_module('tanh', nn.Tanh())\n",
    "encoder_model0.add_module('W1', nn.Linear(16, 3))\n",
    "encoder_model0 = encoder_model0.to(gpu0)\n",
    "\n",
    "node_model0 = nn.Sequential()\n",
    "node_model0.add_module('W0', nn.Linear(3, 16))\n",
    "node_model0.add_module('tanh', nn.Tanh())\n",
    "node_model0.add_module('W1', nn.Linear(16, 3))\n",
    "node_model0 = node_model0.to(gpu0)\n",
    "\n",
    "edge_model0 = nn.Sequential()\n",
    "edge_model0.add_module('W0', nn.Linear(6, 16))\n",
    "edge_model0.add_module('tanh', nn.Tanh())\n",
    "edge_model0.add_module('W1', nn.Linear(16, 1))\n",
    "edge_model0 = edge_model0.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model0.parameters()) + list(node_model0.parameters()) + list(edge_model0.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "e0 = e[:, :e.shape[1]//2].to(gpu0)\n",
    "e1 = e[:, e.shape[1]//2:].to(gpu1)\n",
    "x1 = x.to(gpu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoder_model1 = deepcopy(encoder_model0).to(gpu1)\n",
    "node_model1 = deepcopy(node_model0).to(gpu1)\n",
    "edge_model1 = deepcopy(edge_model0).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_nodes0 = encoder_model0(x)\n",
    "encoded_nodes1 = encoder_model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_nodes0 == encoded_nodes1.to(gpu0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_graph_iters):\n",
    "    scattered_nodes0 = scatter_add_nodes(encoded_nodes0, e0)\n",
    "    scattered_nodes1 = scatter_add_nodes(encoded_nodes1, e1)\n",
    "\n",
    "    scattered_nodes_total0 = scattered_nodes0 + scattered_nodes1.to(scattered_nodes0.device)\n",
    "    encoded_nodes0 = node_model0(scattered_nodes_total0)\n",
    "    encoded_nodes1 = encoded_nodes0.to(gpu1)\n",
    "#     encoded_nodes1 = node_model1(scattered_nodes_total0.to(gpu1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_edges0 = torch.cat([encoded_nodes0[e0[0]], encoded_nodes0[e0[1]]], axis=-1)\n",
    "input_edges1 = torch.cat([encoded_nodes1[e1[0]], encoded_nodes1[e1[1]]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output0 = edge_model0(input_edges0)\n",
    "output1 = edge_model1(input_edges1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0635, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-0.0629, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0632, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss0.backward(retain_graph=True)\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(encoder_model0, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(encoder_model0, encoder_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(node_model0, node_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(node_model0, node_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean_grads(edge_model0, edge_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(edge_model0, edge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_gpu_encoder_model = deepcopy(encoder_model0)\n",
    "multi_gpu_node_model = deepcopy(node_model0)\n",
    "multi_gpu_edge_model = deepcopy(edge_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_encoder_model, multi_gpu_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_node_model, multi_gpu_node_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_edge_model, multi_gpu_edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Multi-GPU Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-GPU Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graph_iters = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (100000, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 4000000), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = nn.Sequential()\n",
    "encoder_model.add_module('W0', nn.Linear(3, 64))\n",
    "encoder_model.add_module('tanh', nn.Tanh())\n",
    "encoder_model.add_module('W1', nn.Linear(64, 3))\n",
    "encoder_model = encoder_model.to(gpu0)\n",
    "\n",
    "node_model = nn.Sequential()\n",
    "node_model.add_module('W0', nn.Linear(3, 64))\n",
    "node_model.add_module('tanh', nn.Tanh())\n",
    "node_model.add_module('W1', nn.Linear(64, 3))\n",
    "node_model = node_model.to(gpu0)\n",
    "\n",
    "edge_model = nn.Sequential()\n",
    "edge_model.add_module('W0', nn.Linear(6, 64))\n",
    "edge_model.add_module('tanh', nn.Tanh())\n",
    "edge_model.add_module('W1', nn.Linear(64, 1))\n",
    "edge_model = edge_model.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model.parameters()) + list(node_model.parameters()) + list(edge_model.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_nodes = encoder_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_graph_iters):\n",
    "    encoded_edges = edge_model(torch.cat([encoded_nodes[e[0]], encoded_nodes[e[1]]], axis=-1))    \n",
    "    scattered_nodes = scatter_add_attention(encoded_nodes, encoded_edges, e)\n",
    "    encoded_nodes = node_model(scattered_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_edges = torch.cat([encoded_nodes[e[0]], encoded_nodes[e[1]]], axis=-1)\n",
    "output = edge_model(input_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"loss\" is the average of the size of each vector\n",
    "loss = output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3759, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_gpu_encoder_model = deepcopy(encoder_model)\n",
    "single_gpu_node_model = deepcopy(node_model)\n",
    "single_gpu_edge_model = deepcopy(edge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 using: 13.86Gb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 0 using: {:.2f}Gb\".format(torch.cuda.memory_stats(device=0)[\"active_bytes.all.peak\"] / 1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1 using: 0.00Gb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 1 using: {:.2f}Gb\".format(torch.cuda.memory_stats(device=1)[\"active_bytes.all.peak\"] / 1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-GPU Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_graph_iters = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "x = torch.randint(0, 5, (100000, 3), device=gpu0).float()\n",
    "e = torch.randint(0, len(x), (2, 4000000), device=gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model0 = nn.Sequential()\n",
    "encoder_model0.add_module('W0', nn.Linear(3, 64))\n",
    "encoder_model0.add_module('tanh', nn.Tanh())\n",
    "encoder_model0.add_module('W1', nn.Linear(64, 3))\n",
    "encoder_model0 = encoder_model0.to(gpu0)\n",
    "\n",
    "node_model0 = nn.Sequential()\n",
    "node_model0.add_module('W0', nn.Linear(3, 64))\n",
    "node_model0.add_module('tanh', nn.Tanh())\n",
    "node_model0.add_module('W1', nn.Linear(64, 3))\n",
    "node_model0 = node_model0.to(gpu0)\n",
    "\n",
    "edge_model0 = nn.Sequential()\n",
    "edge_model0.add_module('W0', nn.Linear(6, 64))\n",
    "edge_model0.add_module('tanh', nn.Tanh())\n",
    "edge_model0.add_module('W1', nn.Linear(64, 1))\n",
    "edge_model0 = edge_model0.to(gpu0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(list(encoder_model0.parameters()) + list(node_model0.parameters()) + list(edge_model0.parameters()), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.88 s, sys: 499 ms, total: 2.38 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "e0 = e[:, :e.shape[1]//2].to(gpu0)\n",
    "e1 = e[:, e.shape[1]//2:].to(gpu1)\n",
    "x1 = x.to(gpu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model1 = deepcopy(encoder_model0).to(gpu1)\n",
    "node_model1 = deepcopy(node_model0).to(gpu1)\n",
    "edge_model1 = deepcopy(edge_model0).to(gpu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_nodes0 = encoder_model0(x)\n",
    "encoded_nodes1 = encoder_model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_nodes0 == encoded_nodes1.to(gpu0)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_graph_iters):\n",
    "    \n",
    "    encoded_edges0 = edge_model0(torch.cat([encoded_nodes0[e0[0]], encoded_nodes0[e0[1]]], axis=-1))    \n",
    "    scattered_nodes0 = scatter_add_attention(encoded_nodes0, encoded_edges0, e0)\n",
    "    \n",
    "    encoded_edges1 = edge_model1(torch.cat([encoded_nodes1[e1[0]], encoded_nodes1[e1[1]]], axis=-1))    \n",
    "    scattered_nodes1 = scatter_add_attention(encoded_nodes1, encoded_edges1, e1)\n",
    "\n",
    "    scattered_nodes_total0 = scattered_nodes0 + scattered_nodes1.to(scattered_nodes0.device)\n",
    "    encoded_nodes0 = node_model0(scattered_nodes_total0)\n",
    "    encoded_nodes1 = encoded_nodes0.to(gpu1)\n",
    "#     encoded_nodes1 = node_model1(scattered_nodes_total0.to(gpu1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edges0 = torch.cat([encoded_nodes0[e0[0]], encoded_nodes0[e0[1]]], axis=-1)\n",
    "input_edges1 = torch.cat([encoded_nodes1[e1[0]], encoded_nodes1[e1[1]]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output0 = edge_model0(input_edges0)\n",
    "output1 = edge_model1(input_edges1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0 = output0.mean()\n",
    "loss1 = output1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3760, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.3759, device='cuda:1', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss0, loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0995, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0.backward(retain_graph=True)\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grads(encoder_model0, encoder_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(encoder_model0, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grads(node_model0, node_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(node_model0, node_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_grads(edge_model0, edge_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(False, device='cuda:0'), tensor(True, device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(edge_model0, edge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gpu_encoder_model = deepcopy(encoder_model0)\n",
    "multi_gpu_node_model = deepcopy(node_model0)\n",
    "multi_gpu_edge_model = deepcopy(edge_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_encoder_model, multi_gpu_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_node_model, multi_gpu_node_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True, device='cuda:0'), True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_models(single_gpu_edge_model, multi_gpu_edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 using: 590.15Mb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 0 using: {:.2f}Mb\".format(torch.cuda.memory_stats(device=0)[\"active_bytes.all.peak\"] / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1 using: 183.02Mb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 1 using: {:.2f}Mb\".format(torch.cuda.memory_stats(device=1)[\"active_bytes.all.peak\"] / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 using: 7.08Gb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 0 using: {:.2f}Gb\".format(torch.cuda.memory_stats(device=0)[\"active_bytes.all.peak\"] / 1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 1 using: 6.85Gb\n"
     ]
    }
   ],
   "source": [
    "print(\"Device 1 using: {:.2f}Gb\".format(torch.cuda.memory_stats(device=1)[\"active_bytes.all.peak\"] / 1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Filter Gradient Play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_dir = \"/global/cscratch1/sd/danieltm/ExaTrkX/trackml-codalab/embedding_processed/1_pt_cut_endcaps_unweighted/train/\"\n",
    "num_events = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_events = os.listdir(input_dir)\n",
    "all_events = sorted([os.path.join(input_dir, event) for event in all_events])\n",
    "loaded_events = []\n",
    "for event in all_events[:num_events]:\n",
    "    try:\n",
    "        loaded_event = torch.load(event, map_location=torch.device('cpu'))\n",
    "        loaded_events.append(loaded_event)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0c224002e96e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVanillaFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         '''\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "class VanillaFilter(nn.module):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        '''\n",
    "        Initialise the Lightning Module that can scan over different filter training regimes\n",
    "        '''\n",
    "\n",
    "        # Construct the MLP architecture\n",
    "        self.input_layer = Linear(hparams[\"in_channels\"]*2 + hparams[\"emb_channels\"]*2, hparams[\"hidden\"])\n",
    "        layers = [Linear(hparams[\"hidden\"], hparams[\"hidden\"]) for _ in range(hparams[\"nb_layer\"]-1)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.output_layer = nn.Linear(hparams[\"hidden\"], 1)\n",
    "        self.layernorm = nn.LayerNorm(hparams[\"hidden\"])\n",
    "        self.batchnorm = nn.BatchNorm1d(num_features=hparams[\"hidden\"], track_running_stats=False)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, e, emb=None):\n",
    "        if emb is not None:\n",
    "            x = self.input_layer(torch.cat([x[e[0]], emb[e[0]], x[e[1]], emb[e[1]]], dim=-1))\n",
    "        else:\n",
    "            x = self.input_layer(torch.cat([x[e[0]], x[e[1]]], dim=-1))\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "            x = self.act(x)\n",
    "            if self.hparams[\"layernorm\"]: x = self.layernorm(x) #Option of LayerNorm\n",
    "            if self.hparams[\"batchnorm\"]: x = self.batchnorm(x) #Option of Batch\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for batch in loaded_events:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
