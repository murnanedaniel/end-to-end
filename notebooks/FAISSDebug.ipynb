{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug FAISS Upgrade to v1.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from time import time as tt\n",
    "import importlib\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from itertools import chain\n",
    "from random import shuffle, sample\n",
    "from scipy.optimize import root_scalar as root\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph, radius_graph\n",
    "import trackml.dataset\n",
    "import torch_geometric\n",
    "from itertools import permutations\n",
    "import itertools\n",
    "from sklearn import metrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import faiss\n",
    "\n",
    "sys.path.append('/global/homes/d/danieltm/ExaTrkX/Tracking-ML-Exa.TrkX/src/Pipelines/Examples')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.stage_utils import get_resume_id, load_config, combo_config, dict_to_args, get_logger, build_model, build_trainer, autocast\n",
    "from LightningModules.Embedding.Models.layerless_embedding import LayerlessEmbedding\n",
    "from LightningModules.Embedding.utils import filter_hit_pt, fetch_pt, fetch_type, load_dataset, graph_intersection, build_edges, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edges(spatial, r_max, k_max, return_indices=False):\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        res = faiss.StandardGpuResources()\n",
    "        D, I = faiss.knn_gpu(res, spatial, spatial, k_max)\n",
    "    elif device == \"cpu\":\n",
    "        index = faiss.IndexFlatL2(spatial.shape[1])\n",
    "        index.add(spatial)\n",
    "        D, I = index.search(spatial, k_max)\n",
    "        \n",
    "    D, I = D[:,1:], I[:,1:]\n",
    "    ind = torch.Tensor.repeat(torch.arange(I.shape[0], device=device), (I.shape[1], 1), 1).T\n",
    "\n",
    "    edge_list = torch.stack([ind[D <= r_max**2], I[D <= r_max**2]])\n",
    "\n",
    "    if return_indices:\n",
    "        return edge_list, D, I, ind\n",
    "    else:\n",
    "        return edge_list\n",
    "    \n",
    "def build_edges_with_index(spatial, index, r_max, k_max, return_indices=False):\n",
    "    \n",
    "    D, I = index.search(spatial, k_max)\n",
    "        \n",
    "    D, I = D[:,1:], I[:,1:]\n",
    "    ind = torch.Tensor.repeat(torch.arange(I.shape[0], device=device), (I.shape[1], 1), 1).T\n",
    "\n",
    "    edge_list = torch.stack([ind[D <= r_max**2], I[D <= r_max**2]])\n",
    "\n",
    "    if return_indices:\n",
    "        return edge_list, D, I, ind\n",
    "    else:\n",
    "        return edge_list\n",
    "\n",
    "def search_index_pytorch(index, x, k, D=None, I=None):\n",
    "    \"\"\"call the search function of an index with pytorch tensor I/O (CPU\n",
    "    and GPU supported)\"\"\"\n",
    "    assert x.is_contiguous()\n",
    "    n, d = x.size()\n",
    "    assert d == index.d\n",
    "\n",
    "    if D is None:\n",
    "        D = torch.empty((n, k), dtype=torch.float32, device=x.device)\n",
    "    else:\n",
    "        assert D.size() == (n, k)\n",
    "\n",
    "    if I is None:\n",
    "        I = torch.empty((n, k), dtype=torch.int64, device=x.device)\n",
    "    else:\n",
    "        assert I.size() == (n, k)\n",
    "    torch.cuda.synchronize()\n",
    "    xptr = swig_ptr_from_FloatTensor(x)\n",
    "    Iptr = swig_ptr_from_LongTensor(I)\n",
    "    Dptr = swig_ptr_from_FloatTensor(D)\n",
    "    index.search_c(n, xptr,\n",
    "                   k, Dptr, Iptr)\n",
    "    torch.cuda.synchronize()\n",
    "    return D, I\n",
    "\n",
    "def swig_ptr_from_FloatTensor(x):\n",
    "    assert x.is_contiguous()\n",
    "    assert x.dtype == torch.float32\n",
    "    return faiss.cast_integer_to_float_ptr(\n",
    "        x.storage().data_ptr() + x.storage_offset() * 4)\n",
    "\n",
    "def swig_ptr_from_LongTensor(x):\n",
    "    assert x.is_contiguous()\n",
    "    assert x.dtype == torch.int64, 'dtype=%s' % x.dtype\n",
    "    return faiss.cast_integer_to_long_ptr(\n",
    "        x.storage().data_ptr() + x.storage_offset() * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss.contrib.torch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "d = 8\n",
    "nb = 100000\n",
    "nq = 10\n",
    "k = 500\n",
    "r = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76 µs, sys: 90 µs, total: 166 µs\n",
      "Wall time: 172 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spatial = torch.rand(nb, d, dtype=torch.float32, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 168 ms, sys: 205 ms, total: 373 ms\n",
      "Wall time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_list = build_edges(spatial, r, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.47 ms, total: 1.47 ms\n",
      "Wall time: 1.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_index = faiss.GpuIndexFlatL2(res, d)\n",
    "gpu_index.add(spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 75 ms, total: 265 ms\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_list = build_edges_with_index(spatial, gpu_index, r, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.29 ms, sys: 0 ns, total: 2.29 ms\n",
      "Wall time: 1.92 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = gpu_index.search(spatial, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 86.4 ms, sys: 66.3 ms, total: 153 ms\n",
      "Wall time: 90.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = D[:,1:], I[:,1:]\n",
    "ind = torch.Tensor.repeat(torch.arange(I.shape[0]), (I.shape[1], 1), 1).T.to(device)\n",
    "edge_list = torch.stack([ind[D <= r**2], I[D <= r**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.94 ms, sys: 0 ns, total: 1.94 ms\n",
      "Wall time: 1.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = D[:,1:], I[:,1:]\n",
    "ind = torch.Tensor.repeat(torch.arange(I.shape[0], device=device), (I.shape[1], 1), 1).T\n",
    "edge_list = torch.stack([ind[D <= r**2], I[D <= r**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = torch.rand(nb, d, dtype=torch.float32, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 ms, sys: 0 ns, total: 1.48 ms\n",
      "Wall time: 1.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpu_index = faiss.GpuIndexFlatL2(res, d)\n",
    "gpu_index.add(spatial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 ms, sys: 0 ns, total: 2.75 ms\n",
      "Wall time: 2.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = gpu_index.search(spatial, k)\n",
    "\n",
    "D, I = D[:,1:], I[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 ms, sys: 0 ns, total: 3.22 ms\n",
      "Wall time: 2.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ind = torch.Tensor.repeat(torch.arange(I.shape[0], device=device), (I.shape[1], 1), 1).T\n",
    "edge_list = torch.stack([ind[D <= r**2], I[D <= r**2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
