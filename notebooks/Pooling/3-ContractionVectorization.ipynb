{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speeding up Edge Contraction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X] Create toy graph\n",
    "- [X] Get timings of original algorithm\n",
    "- [X] Implement CuGraph connected components\n",
    "- [X] Get CC timings\n",
    "- [ ] Implement CC into the PyGeometric function\n",
    "- [ ] Explore a vectorized version of original idea - only one edge contracted per node\n",
    "- [ ] Explore sorting vs. random choice of edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100000\n",
    "num_edges = 1000000\n",
    "x = torch.rand((num_nodes, 3), device=device).float()\n",
    "e = torch.randint(0, len(x), (2, num_edges), device=device).long()\n",
    "edge_score = torch.cat([\n",
    "    torch.rand(int(num_edges*0.9), device=device).float()*0.4,\n",
    "    torch.rand(int(num_edges*0.1), device=device).float()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def __merge_edges_original__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx].item()\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx].item()\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 15.6 ms, total: 6.29 s\n",
      "Wall time: 6.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_x, new_edge_index, new_batch = __merge_edges__(x, e, torch.zeros(x.shape[0], device=device).long(), edge_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CuGraph Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cugraph\n",
    "import cudf\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "from torch.utils.dlpack import from_dlpack, to_dlpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "passing_edges = e[:, edge_score > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.48 ms, total: 1.48 ms\n",
      "Wall time: 1.22 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/exatrkx-test/lib/python3.7/site-packages/cudf/io/dlpack.py:33: UserWarning: WARNING: cuDF from_dlpack() assumes column-major (Fortran order) input. If the input tensor is row-major, transpose it before passing it to this function.\n",
      "  res = libdlpack.from_dlpack(pycapsule_obj)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "passing_edges = cudf.from_dlpack(to_dlpack(passing_edges.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.6 ms, sys: 3.87 ms, total: 55.5 ms\n",
      "Wall time: 55.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "G = cugraph.Graph()\n",
    "G.from_cudf_edgelist(passing_edges, source=0, destination=1, edge_attr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.61 ms, sys: 3.73 ms, total: 12.3 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "labels = cugraph.components.connectivity.weakly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This all seems to work fine, so let's build it into a new method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def __merge_edges__(x, edge_index, batch, edge_score):\n",
    "        \n",
    "    nodes_remaining = set(range(x.size(0)))\n",
    "\n",
    "    cluster = torch.empty_like(batch, device=x.device).long()\n",
    "    edge_argsort = torch.argsort(edge_score, descending=True)\n",
    "\n",
    "    # Iterate through all edges, selecting it if it is not incident to\n",
    "    # another already chosen edge.\n",
    "    i = 0\n",
    "    new_edge_indices = []\n",
    "   # edge_index_cpu = edge_index.cpu()\n",
    "    for edge_idx in edge_argsort.tolist():\n",
    "        source = edge_index[0, edge_idx]\n",
    "        if source not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        target = edge_index[1, edge_idx]\n",
    "        if target not in nodes_remaining:\n",
    "            continue\n",
    "\n",
    "        new_edge_indices.append(edge_idx)\n",
    "\n",
    "        cluster[source] = i\n",
    "        nodes_remaining.remove(source)\n",
    "\n",
    "        if source != target:\n",
    "            cluster[target] = i\n",
    "            nodes_remaining.remove(target)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # The remaining nodes are simply kept.\n",
    "    for node_idx in nodes_remaining:\n",
    "        cluster[node_idx] = i\n",
    "        i += 1\n",
    "#     cluster = cluster.to(x.device)\n",
    "\n",
    "    # We compute the new features as an addition of the old ones.\n",
    "    new_x = scatter_add(x, cluster, dim=0, dim_size=i)\n",
    "    new_edge_score = edge_score[new_edge_indices]\n",
    "    if len(nodes_remaining) > 0:\n",
    "        remaining_score = x.new_ones(\n",
    "            (new_x.size(0) - len(new_edge_indices), ))\n",
    "        new_edge_score = torch.cat([new_edge_score, remaining_score])\n",
    "    new_x = new_x * new_edge_score.view(-1, 1)\n",
    "\n",
    "    N = new_x.size(0)\n",
    "    new_edge_index, _ = coalesce(cluster[edge_index], None, N, N)\n",
    "\n",
    "    new_batch = x.new_empty(new_x.size(0), dtype=torch.long, device=device)\n",
    "#     batch = batch.to(x.device)\n",
    "    new_batch = new_batch.scatter_(0, cluster, batch)\n",
    "\n",
    "#     unpool_info = self.unpool_description(edge_index=edge_index,\n",
    "#                                           cluster=cluster, batch=batch,\n",
    "#                                           new_edge_score=new_edge_score)\n",
    "\n",
    "#     return new_x, new_edge_index, new_batch, unpool_info\n",
    "    return new_x, new_edge_index, new_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-node, One-edge Constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 869 µs, sys: 0 ns, total: 869 µs\n",
      "Wall time: 511 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([621952, 905298, 928899,  ..., 988551, 436959, 991108], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get timing for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 967 µs, sys: 2.25 ms, total: 3.22 ms\n",
      "Wall time: 2.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_score_0, max_indices_0 = scatter_max(edge_score, e[0], dim=0, dim_size=x.shape[0])\n",
    "max_score_1, max_indices_1 = scatter_max(edge_score, e[1], dim=0, dim_size=x.shape[0])\n",
    "\n",
    "stacked_score, stacked_indices = torch.stack([max_score_0, max_score_1]), torch.stack([max_indices_0, max_indices_1]).T\n",
    "top_score = torch.argmax(stacked_score, dim=0)\n",
    "\n",
    "max_indices = torch.zeros(len(top_score), dtype=torch.long, device=device)\n",
    "\n",
    "max_indices[max_score_0 > max_score_1] = max_indices_0[max_score_0 > max_score_1]\n",
    "max_indices[max_score_1 > max_score_0] = max_indices_1[max_score_1 > max_score_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 ms, sys: 0 ns, total: 1.46 ms\n",
      "Wall time: 973 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([     10,      23,      33,  ...,  999998,  999999, 1000000],\n",
       "        device='cuda:0'),\n",
       " tensor([1, 1, 1,  ..., 2, 1, 7], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.unique(stacked_indices, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExatrkxTest",
   "language": "python",
   "name": "exatrkx-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
